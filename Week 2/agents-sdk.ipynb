{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa5c648-3f00-42bc-949a-815ac895efc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\ryahj\\cascadeprojects\\ai-bootcamp\\ai-bootcamp\\.venv\\lib\\site-packages (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f914c25-7686-4c77-a6c2-6860164c9418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca815991-f0b7-49f1-8942-1546e79d358c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90cb86c8-7610-4928-972c-fc9cc2b69c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16489899-4d98-4d49-ae3d-58fdd4b844a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m164 packages\u001b[0m \u001b[2min 790ms\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`transformers==4.57.0` is yanked (reason: \"Error in the setup causing installation issues\")\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 2.09s\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 574ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 723ms\u001b[0m\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenai\u001b[0m\u001b[2m==1.109.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mopenai-agents\u001b[0m\u001b[2m==0.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenai-agents\u001b[0m\u001b[2m==0.3.3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add openai-agents==0.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb70baf-3161-4b47-bb0d-923dab1e9452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m164 packages\u001b[0m \u001b[2min 490ms\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1m`transformers==4.57.0` is yanked (reason: \"Error in the setup causing installation issues\")\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m144 packages\u001b[0m \u001b[2min 150ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv remove openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff722bdc-ff1d-47fc-9802-aeff609d6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7a2329-c778-4d85-8e54-f75299372944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf668cb-2542-4f47-9b4a-f8fb2be1103b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, function_tool, Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba2d423-22d8-4aaf-bcfc-63a55942d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "62204f3a-86d4-4bbe-8188-37f0f421c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_url(url: str) -> str:\n",
    "    jina_reader_base_url = 'https://r.jina.ai/'\n",
    "    jina_reader_url = jina_reader_base_url + url\n",
    "    response = requests.get(jina_reader_url)\n",
    "    return response.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f266ed11-c173-4b76-99b5-7fd29ac966db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import Optional\n",
    "\n",
    "reader_url_prefix = \"https://r.jina.ai/\"\n",
    "\n",
    "def get_page_content(url: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Fetch the Markdown content of a web page using the Jina Reader service.\n",
    "\n",
    "    This function prepends the Jina Reader proxy URL to the provided `url`,\n",
    "    sends a GET request with a timeout, and decodes the response as UTF-8 text.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the page to fetch.\n",
    "\n",
    "    Returns:\n",
    "        Optional[str]: The Markdown-formatted content of the page if the request\n",
    "        succeeds; otherwise, None.\n",
    "\n",
    "    Raises:\n",
    "        None: All network or decoding errors are caught and suppressed.\n",
    "               Logs or error messages could be added as needed.\n",
    "    \"\"\"\n",
    "    reader_url = reader_url_prefix + url\n",
    "\n",
    "    try:\n",
    "        response = requests.get(reader_url, timeout=10)\n",
    "        response.raise_for_status()  # raises for 4xx/5xx HTTP errors\n",
    "        return response.content.decode(\"utf-8\")\n",
    "    except (requests.exceptions.RequestException, UnicodeDecodeError) as e:\n",
    "        # Optional: log or print the error for debugging\n",
    "        print(f\"Error fetching content from {url}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b412e63-ce3e-43e6-b328-199deed6c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = fetch_url('https://datatalks.club')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2542978e-ceca-42a6-b4c7-e11c08648003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Welcome to DataTalks.Club\n",
      "\n",
      "URL Source: https://datatalks.club/\n",
      "\n",
      "Published Time: Thu, 16 Oct 2025 09:40:58 GMT\n",
      "\n",
      "Markdown Content:\n",
      "Welcome to DataTalks.Club\n",
      "\n",
      "===============\n",
      "\n",
      "AI Dev Tools Zoomcamp: Learn AI-powered coding assistants and agents[Register here!](https://airtable.com/appJRFiWKHBgmEt70/shrpw7rk55Ewr1jCG)\n",
      "\n",
      "DataTalks.Club\n",
      "--------------\n",
      "\n",
      "[Articles](https://datatalks.club/articles.html)[Slack](https://datatalks.club/slack.html)[Events](https://datatalks.club/events.html)[Podcast](https://datatalks.club/podcast.html)[Books](https://datatalks.club/books.html)[Courses](https://datatalks.club/blog/guide-to-free-online-courses-at-datatalks-club.html)\n",
      "\n",
      "* * *\n",
      "\n",
      "The place to talk about data\n",
      "============================\n",
      "\n",
      "Global online community of data science professionals, ML engineers, and AI practitioners\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "Subscribe to our weekly newsletter and join our Slack.\n",
      "\n",
      " We'll keep you informed about everything happening in the Club.\n",
      "\n",
      "Email \n",
      "\n",
      " Join \n",
      "\n",
      " You'll get an invite within 3 minutes \n",
      "\n",
      "![Image 4: Data science discussions and talks](https://datatalks.club/images/landing/talks.jpg)\n",
      "\n",
      "#### Talk about data, machine\n",
      "\n",
      " learning, and engineering\n",
      "\n",
      "![Image 5: Data science events and courses](https://datatalks.club/images/landing/events.jpg)\n",
      "\n",
      "#### Attend weekly events\n",
      "\n",
      " and learn from free courses\n",
      "\n",
      "![Image 6: Career guidance and mentorship](https://datatalks.club/images/landing/career.jpg)\n",
      "\n",
      "#### Ask career questions and\n",
      "\n",
      " discuss career options\n",
      "\n",
      "* * *\n",
      "\n",
      "#### Upcoming events\n",
      "\n",
      "*   [How to Build and Evaluate AI systems in the Age of LLMs](https://luma.com/w65omumd) on 21 Oct 2025 by [Hugo Bowne-Anderson](https://datatalks.club/people/hugobowneanderson.html)\n",
      "*   [Deep Learning with PyTorch](https://luma.com/vc02zy6a) on 21 Oct 2025 by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html)\n",
      "*   [From Black-Box Systems to Augmented Decision-Making](https://luma.com/gqmsx9zd) on 28 Oct 2025 by [Anusha Akkina](https://datatalks.club/people/anushaakkina.html)\n",
      "*   [Practical guide: Fine-tuning Qwen3 with LoRA](https://luma.com/n41kqkfh) on 30 Oct 2025 by [Ivan Potapov](https://datatalks.club/people/ivanpotapov.html)\n",
      "*   [AI Dev Tools Zoomcamp 2025 Pre-Course Live Q&A](https://luma.com/6p356li5) on 04 Nov 2025 by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html)\n",
      "*   [Reinventing a Career in Tech](https://luma.com/ifmqg2xb) on 17 Nov 2025 by [Xia He-Bleinagel](https://datatalks.club/people/xiahebleinagel.html)\n",
      "*   [AI Dev Tools Zoomcamp 2025 Course Launch](https://luma.com/80ve8r1u) on 18 Nov 2025 by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html)\n",
      "*   [The Future of AI Agents](https://luma.com/0s0dcpdl) on 10 Feb 2026 by [Aditya Gautam](https://datatalks.club/people/adityagautam.html)\n",
      "\n",
      "Check [events](https://datatalks.club/events.html) for all past events. You can also subscribe to [our Google calendar](https://calendar.google.com/calendar/?cid=ZjhxaWRqbnEwamhzY3A4ODA5azFlZ2hzNjBAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ) to get notified about all our events.\n",
      "\n",
      "#### Latest podcast episodes\n",
      "\n",
      "*   [Lessons from Two Decades of AI](https://datatalks.club/podcast/s21e07-lessons-from-two-decades-of-ai.html) with [Micheal Lanham](https://datatalks.club/people/micheallanham.html)\n",
      "*   [From Astronomy to Applied ML](https://datatalks.club/podcast/s21e05-from-astronomy-to-applied-ml.html) with [Daniel Egbo](https://datatalks.club/people/danielegbo.html)\n",
      "*   [From Medicine to Machine Learning: How Public Learning Turned into a Career](https://datatalks.club/podcast/s21e03-from-medicine-to-machine-learning-how-public-learning-turned-into-career.html) with [Pastor Soto](https://datatalks.club/people/pastorsoto.html)\n",
      "*   [Mindful Data Strategy: From Pipelines to Business Impact](https://datatalks.club/podcast/s21e02-mindful-data-strategy-from-pipelines-to-business-impact.html) with [Lior Barak](https://datatalks.club/people/liorbarak.html)\n",
      "*   [From Simulation Algorithms to Production-Grade Data Systems](https://datatalks.club/podcast/s21e01-from-simulation-algorithms-to-production-grade-data-systems.html) with [Orell Garten](https://datatalks.club/people/orellgarten.html)\n",
      "\n",
      "Check the [podcast](https://datatalks.club/podcast.html) page for all past podcast episodes.\n",
      "\n",
      "#### Our Sponsors\n",
      "\n",
      "[![Image 7: dltHub](https://datatalks.club/images/partners/dlthub.png)](https://dlthub.com/)\n",
      "\n",
      "[![Image 8: Astronomer](https://datatalks.club/images/partners/astronomer.png)](https://www.astronomer.io/)\n",
      "\n",
      "[![Image 9: Arize AI](https://datatalks.club/images/partners/arize.png)](https://arize.com/model-monitoring/)\n",
      "\n",
      "#### Book of the week\n",
      "\n",
      "Check the [book of the week](https://datatalks.club/books.html) page for more books!\n",
      "\n",
      "#### Latest articles\n",
      "\n",
      "*   [AI Dev Tools Zoomcamp 2025: Free Course to Master Coding Assistants, Agents, and Automation](https://datatalks.club/blog/ai-dev-tools-zoomcamp-2025-free-course-to-master-coding-assistants-agents-and-automation.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "*   [20+ Best Data Science Slack Communities to Join in 2025](https://datatalks.club/blog/slack-communities.html) by [Alexey Grigorev](https://datatalks.club/people/alexeygrigorev.html), [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "*   [A Guide to Free Online Courses at DataTalks.Club](https://datatalks.club/blog/guide-to-free-online-courses-at-datatalks-club.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "*   [Data Engineering Zoomcamp 2026: Free Data Engineering Course and Certification](https://datatalks.club/blog/data-engineering-zoomcamp.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "*   [ML Zoomcamp 2025: Free Machine Learning Engineering Course and Certification](https://datatalks.club/blog/machine-learning-zoomcamp.html) by [Valeriia Kuka](https://datatalks.club/people/valeriiakuka.html)\n",
      "\n",
      "* * *\n",
      "\n",
      " DataTalks.Club. Hosted on [GitHub Pages](https://github.com/DataTalksClub/datatalksclub.github.io). We use cookies.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c0e392e-1109-492c-a342-6a46017a5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_agent = Agent(\n",
    "    name='web_agent',\n",
    "    instructions=\"you're a helpful assistant\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[function_tool(fetch_url)]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fb4f8f7-94e7-4673-a577-3a88c6cb9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "824440e2-2384-4df7-a4d2-b9896eac6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8010074f-99c7-4377-95dd-f6a0254561db",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"whats is this page about? https://openai.github.io/openai-agents-python/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98f83336-8b6c-47ef-b40c-d0006b3d810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryahj\\AppData\\Local\\Temp\\ipykernel_27776\\3288517736.py:1: RuntimeWarning: coroutine 'Runner.run' was never awaited\n",
      "  results = await runner.run(web_agent, input=question)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "results = await runner.run(web_agent, input=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b9a374e-305e-459f-bcc9-d772a19e400a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCallItem(agent=Agent(name='web_agent', handoff_description=None, tools=[FunctionTool(name='fetch_url', description='', params_json_schema={'properties': {'url': {'title': 'Url', 'type': 'string'}}, 'required': ['url'], 'title': 'fetch_url_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000024893DBDE40>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"you're a helpful assistant\", prompt=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseFunctionToolCall(arguments='{\"url\":\"https://openai.github.io/openai-agents-python/\"}', call_id='call_MJbkQddNn4ETaRG8mdvydLNB', name='fetch_url', type='function_call', id='fc_031eeed2da53f7110068f19280bb1c8193b542f1c31518e1cb', status='completed'), type='tool_call_item'),\n",
       " ToolCallOutputItem(agent=Agent(name='web_agent', handoff_description=None, tools=[FunctionTool(name='fetch_url', description='', params_json_schema={'properties': {'url': {'title': 'Url', 'type': 'string'}}, 'required': ['url'], 'title': 'fetch_url_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000024893DBDE40>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"you're a helpful assistant\", prompt=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item={'call_id': 'call_MJbkQddNn4ETaRG8mdvydLNB', 'output': 'Title: OpenAI Agents SDK\\n\\nURL Source: https://openai.github.io/openai-agents-python/\\n\\nPublished Time: Fri, 17 Oct 2025 00:27:03 GMT\\n\\nMarkdown Content:\\nOpenAI Agents SDK\\n\\n===============\\n- [x] - [x] \\n\\n[Skip to content](https://openai.github.io/openai-agents-python/#openai-agents-sdk)\\n\\n[![Image 1: logo](https://openai.github.io/openai-agents-python/assets/logo.svg)](https://openai.github.io/openai-agents-python/ \"OpenAI Agents SDK\")\\n\\n OpenAI Agents SDK \\n\\n Intro \\n\\n*   [English](https://openai.github.io/openai-agents-python/)\\n*   [日本語](https://openai.github.io/openai-agents-python/ja/)\\n*   [한국어](https://openai.github.io/openai-agents-python/ko/)\\n*   [简体中文](https://openai.github.io/openai-agents-python/zh/)\\n\\n Initializing search \\n\\n[openai-agents-python](https://github.com/openai/openai-agents-python \"Go to repository\")\\n\\n[![Image 2: logo](https://openai.github.io/openai-agents-python/assets/logo.svg)](https://openai.github.io/openai-agents-python/ \"OpenAI Agents SDK\") OpenAI Agents SDK  \\n\\n[openai-agents-python](https://github.com/openai/openai-agents-python \"Go to repository\")\\n\\n*   - [x]  Intro  [Intro](https://openai.github.io/openai-agents-python/) Table of contents  \\n    *   [Why use the Agents SDK](https://openai.github.io/openai-agents-python/#why-use-the-agents-sdk)\\n    *   [Installation](https://openai.github.io/openai-agents-python/#installation)\\n    *   [Hello world example](https://openai.github.io/openai-agents-python/#hello-world-example)\\n\\n*   [Quickstart](https://openai.github.io/openai-agents-python/quickstart/)\\n*   [Examples](https://openai.github.io/openai-agents-python/examples/)\\n*   - [x]  Documentation   Documentation  \\n    *   [Agents](https://openai.github.io/openai-agents-python/agents/)\\n    *   [Running agents](https://openai.github.io/openai-agents-python/running_agents/)\\n    *   - [x]  Sessions   Sessions  \\n        *   [Sessions](https://openai.github.io/openai-agents-python/sessions/)\\n        *   [SQLAlchemy Sessions](https://openai.github.io/openai-agents-python/sessions/sqlalchemy_session/)\\n        *   [Advanced SQLite Sessions](https://openai.github.io/openai-agents-python/sessions/advanced_sqlite_session/)\\n        *   [Encrypted Sessions](https://openai.github.io/openai-agents-python/sessions/encrypted_session/)\\n\\n    *   [Results](https://openai.github.io/openai-agents-python/results/)\\n    *   [Streaming](https://openai.github.io/openai-agents-python/streaming/)\\n    *   [REPL utility](https://openai.github.io/openai-agents-python/repl/)\\n    *   [Tools](https://openai.github.io/openai-agents-python/tools/)\\n    *   [Model context protocol (MCP)](https://openai.github.io/openai-agents-python/mcp/)\\n    *   [Handoffs](https://openai.github.io/openai-agents-python/handoffs/)\\n    *   [Tracing](https://openai.github.io/openai-agents-python/tracing/)\\n    *   [Context management](https://openai.github.io/openai-agents-python/context/)\\n    *   [Guardrails](https://openai.github.io/openai-agents-python/guardrails/)\\n    *   [Orchestrating multiple agents](https://openai.github.io/openai-agents-python/multi_agent/)\\n    *   [Usage](https://openai.github.io/openai-agents-python/usage/)\\n    *   - [x]  Models   Models  \\n        *   [Models](https://openai.github.io/openai-agents-python/models/)\\n        *   [Using any model via LiteLLM](https://openai.github.io/openai-agents-python/models/litellm/)\\n\\n    *   [Configuring the SDK](https://openai.github.io/openai-agents-python/config/)\\n    *   [Agent Visualization](https://openai.github.io/openai-agents-python/visualization/)\\n    *   [Release process/changelog](https://openai.github.io/openai-agents-python/release/)\\n    *   - [x]  Voice agents   Voice agents  \\n        *   [Quickstart](https://openai.github.io/openai-agents-python/voice/quickstart/)\\n        *   [Pipelines and workflows](https://openai.github.io/openai-agents-python/voice/pipeline/)\\n        *   [Tracing](https://openai.github.io/openai-agents-python/voice/tracing/)\\n\\n    *   - [x]  Realtime agents   Realtime agents  \\n        *   [Quickstart](https://openai.github.io/openai-agents-python/realtime/quickstart/)\\n        *   [Guide](https://openai.github.io/openai-agents-python/realtime/guide/)\\n\\n*   - [x]  API Reference   API Reference  \\n    *   - [x]  Agents   Agents  \\n        *   [Agents module](https://openai.github.io/openai-agents-python/ref/)\\n        *   [Agents](https://openai.github.io/openai-agents-python/ref/agent/)\\n        *   [Runner](https://openai.github.io/openai-agents-python/ref/run/)\\n        *   [Memory](https://openai.github.io/openai-agents-python/ref/memory/)\\n        *   [repl](https://openai.github.io/openai-agents-python/ref/repl/)\\n        *   [Tools](https://openai.github.io/openai-agents-python/ref/tool/)\\n        *   [Tool Context](https://openai.github.io/openai-agents-python/ref/tool_context/)\\n        *   [Results](https://openai.github.io/openai-agents-python/ref/result/)\\n        *   [Streaming events](https://openai.github.io/openai-agents-python/ref/stream_events/)\\n        *   [Handoffs](https://openai.github.io/openai-agents-python/ref/handoffs/)\\n        *   [Lifecycle](https://openai.github.io/openai-agents-python/ref/lifecycle/)\\n        *   [Items](https://openai.github.io/openai-agents-python/ref/items/)\\n        *   [Run context](https://openai.github.io/openai-agents-python/ref/run_context/)\\n        *   [Tool Context](https://openai.github.io/openai-agents-python/ref/tool_context/)\\n        *   [Usage](https://openai.github.io/openai-agents-python/ref/usage/)\\n        *   [Exceptions](https://openai.github.io/openai-agents-python/ref/exceptions/)\\n        *   [Guardrails](https://openai.github.io/openai-agents-python/ref/guardrail/)\\n        *   [Model settings](https://openai.github.io/openai-agents-python/ref/model_settings/)\\n        *   [Agent output](https://openai.github.io/openai-agents-python/ref/agent_output/)\\n        *   [Function schema](https://openai.github.io/openai-agents-python/ref/function_schema/)\\n        *   [Model interface](https://openai.github.io/openai-agents-python/ref/models/interface/)\\n        *   [OpenAI Chat Completions model](https://openai.github.io/openai-agents-python/ref/models/openai_chatcompletions/)\\n        *   [OpenAI Responses model](https://openai.github.io/openai-agents-python/ref/models/openai_responses/)\\n        *   [MCP Servers](https://openai.github.io/openai-agents-python/ref/mcp/server/)\\n        *   [MCP Util](https://openai.github.io/openai-agents-python/ref/mcp/util/)\\n\\n    *   - [x]  Tracing   Tracing  \\n        *   [Tracing module](https://openai.github.io/openai-agents-python/ref/tracing/)\\n        *   [Creating traces/spans](https://openai.github.io/openai-agents-python/ref/tracing/create/)\\n        *   [Traces](https://openai.github.io/openai-agents-python/ref/tracing/traces/)\\n        *   [Spans](https://openai.github.io/openai-agents-python/ref/tracing/spans/)\\n        *   [Processor interface](https://openai.github.io/openai-agents-python/ref/tracing/processor_interface/)\\n        *   [Processors](https://openai.github.io/openai-agents-python/ref/tracing/processors/)\\n        *   [Scope](https://openai.github.io/openai-agents-python/ref/tracing/scope/)\\n        *   [Setup](https://openai.github.io/openai-agents-python/ref/tracing/setup/)\\n        *   [Span data](https://openai.github.io/openai-agents-python/ref/tracing/span_data/)\\n        *   [Util](https://openai.github.io/openai-agents-python/ref/tracing/util/)\\n\\n    *   - [x]  Realtime   Realtime  \\n        *   [RealtimeAgent](https://openai.github.io/openai-agents-python/ref/realtime/agent/)\\n        *   [RealtimeRunner](https://openai.github.io/openai-agents-python/ref/realtime/runner/)\\n        *   [RealtimeSession](https://openai.github.io/openai-agents-python/ref/realtime/session/)\\n        *   [Realtime Events](https://openai.github.io/openai-agents-python/ref/realtime/events/)\\n        *   [Realtime Configuration](https://openai.github.io/openai-agents-python/ref/realtime/config/)\\n        *   [Model](https://openai.github.io/openai-agents-python/ref/realtime/model/)\\n\\n    *   - [x]  Voice   Voice  \\n        *   [Pipeline](https://openai.github.io/openai-agents-python/ref/voice/pipeline/)\\n        *   [Workflow](https://openai.github.io/openai-agents-python/ref/voice/workflow/)\\n        *   [Input](https://openai.github.io/openai-agents-python/ref/voice/input/)\\n        *   [Result](https://openai.github.io/openai-agents-python/ref/voice/result/)\\n        *   [Pipeline Config](https://openai.github.io/openai-agents-python/ref/voice/pipeline_config/)\\n        *   [Events](https://openai.github.io/openai-agents-python/ref/voice/events/)\\n        *   [Exceptions](https://openai.github.io/openai-agents-python/ref/voice/exceptions/)\\n        *   [Model](https://openai.github.io/openai-agents-python/ref/voice/model/)\\n        *   [Utils](https://openai.github.io/openai-agents-python/ref/voice/utils/)\\n        *   [OpenAIVoiceModelProvider](https://openai.github.io/openai-agents-python/ref/voice/models/openai_provider/)\\n        *   [OpenAI STT](https://openai.github.io/openai-agents-python/ref/voice/models/openai_stt/)\\n        *   [OpenAI TTS](https://openai.github.io/openai-agents-python/ref/voice/models/openai_tts/)\\n\\n    *   - [x]  Extensions   Extensions  \\n        *   [Handoff filters](https://openai.github.io/openai-agents-python/ref/extensions/handoff_filters/)\\n        *   [Handoff prompt](https://openai.github.io/openai-agents-python/ref/extensions/handoff_prompt/)\\n        *   [LiteLLM Models](https://openai.github.io/openai-agents-python/ref/extensions/litellm/)\\n        *   [SQLAlchemySession](https://openai.github.io/openai-agents-python/ref/extensions/memory/sqlalchemy_session/)\\n        *   [EncryptedSession](https://openai.github.io/openai-agents-python/ref/extensions/memory/encrypt_session/)\\n        *   [AdvancedSQLiteSession](https://openai.github.io/openai-agents-python/ref/extensions/memory/advanced_sqlite_session/)\\n\\n Table of contents  \\n*   [Why use the Agents SDK](https://openai.github.io/openai-agents-python/#why-use-the-agents-sdk)\\n*   [Installation](https://openai.github.io/openai-agents-python/#installation)\\n*   [Hello world example](https://openai.github.io/openai-agents-python/#hello-world-example)\\n\\nOpenAI Agents SDK\\n=================\\n\\nThe [OpenAI Agents SDK](https://github.com/openai/openai-agents-python) enables you to build agentic AI apps in a lightweight, easy-to-use package with very few abstractions. It\\'s a production-ready upgrade of our previous experimentation for agents, [Swarm](https://github.com/openai/swarm/tree/main). The Agents SDK has a very small set of primitives:\\n\\n*   **Agents**, which are LLMs equipped with instructions and tools\\n*   **Handoffs**, which allow agents to delegate to other agents for specific tasks\\n*   **Guardrails**, which enable validation of agent inputs and outputs\\n*   **Sessions**, which automatically maintains conversation history across agent runs\\n\\nIn combination with Python, these primitives are powerful enough to express complex relationships between tools and agents, and allow you to build real-world applications without a steep learning curve. In addition, the SDK comes with built-in **tracing** that lets you visualize and debug your agentic flows, as well as evaluate them and even fine-tune models for your application.\\n\\nWhy use the Agents SDK\\n----------------------\\n\\nThe SDK has two driving design principles:\\n\\n1.   Enough features to be worth using, but few enough primitives to make it quick to learn.\\n2.   Works great out of the box, but you can customize exactly what happens.\\n\\nHere are the main features of the SDK:\\n\\n*   Agent loop: Built-in agent loop that handles calling tools, sending results to the LLM, and looping until the LLM is done.\\n*   Python-first: Use built-in language features to orchestrate and chain agents, rather than needing to learn new abstractions.\\n*   Handoffs: A powerful feature to coordinate and delegate between multiple agents.\\n*   Guardrails: Run input validations and checks in parallel to your agents, breaking early if the checks fail.\\n*   Sessions: Automatic conversation history management across agent runs, eliminating manual state handling.\\n*   Function tools: Turn any Python function into a tool, with automatic schema generation and Pydantic-powered validation.\\n*   Tracing: Built-in tracing that lets you visualize, debug and monitor your workflows, as well as use the OpenAI suite of evaluation, fine-tuning and distillation tools.\\n\\nInstallation\\n------------\\n\\n```\\npip install openai-agents\\n```\\n\\nHello world example\\n-------------------\\n\\n```\\nfrom agents import Agent, Runner\\n\\nagent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\\n\\nresult = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\\nprint(result.final_output)\\n\\n# Code within the code,\\n# Functions calling themselves,\\n# Infinite loop\\'s dance.\\n```\\n\\n(_If running this, ensure you set the `OPENAI\\\\_API\\\\_KEY` environment variable_)\\n\\n```\\nexport OPENAI_API_KEY=sk-...\\n```\\n', 'type': 'function_call_output'}, output='Title: OpenAI Agents SDK\\n\\nURL Source: https://openai.github.io/openai-agents-python/\\n\\nPublished Time: Fri, 17 Oct 2025 00:27:03 GMT\\n\\nMarkdown Content:\\nOpenAI Agents SDK\\n\\n===============\\n- [x] - [x] \\n\\n[Skip to content](https://openai.github.io/openai-agents-python/#openai-agents-sdk)\\n\\n[![Image 1: logo](https://openai.github.io/openai-agents-python/assets/logo.svg)](https://openai.github.io/openai-agents-python/ \"OpenAI Agents SDK\")\\n\\n OpenAI Agents SDK \\n\\n Intro \\n\\n*   [English](https://openai.github.io/openai-agents-python/)\\n*   [日本語](https://openai.github.io/openai-agents-python/ja/)\\n*   [한국어](https://openai.github.io/openai-agents-python/ko/)\\n*   [简体中文](https://openai.github.io/openai-agents-python/zh/)\\n\\n Initializing search \\n\\n[openai-agents-python](https://github.com/openai/openai-agents-python \"Go to repository\")\\n\\n[![Image 2: logo](https://openai.github.io/openai-agents-python/assets/logo.svg)](https://openai.github.io/openai-agents-python/ \"OpenAI Agents SDK\") OpenAI Agents SDK  \\n\\n[openai-agents-python](https://github.com/openai/openai-agents-python \"Go to repository\")\\n\\n*   - [x]  Intro  [Intro](https://openai.github.io/openai-agents-python/) Table of contents  \\n    *   [Why use the Agents SDK](https://openai.github.io/openai-agents-python/#why-use-the-agents-sdk)\\n    *   [Installation](https://openai.github.io/openai-agents-python/#installation)\\n    *   [Hello world example](https://openai.github.io/openai-agents-python/#hello-world-example)\\n\\n*   [Quickstart](https://openai.github.io/openai-agents-python/quickstart/)\\n*   [Examples](https://openai.github.io/openai-agents-python/examples/)\\n*   - [x]  Documentation   Documentation  \\n    *   [Agents](https://openai.github.io/openai-agents-python/agents/)\\n    *   [Running agents](https://openai.github.io/openai-agents-python/running_agents/)\\n    *   - [x]  Sessions   Sessions  \\n        *   [Sessions](https://openai.github.io/openai-agents-python/sessions/)\\n        *   [SQLAlchemy Sessions](https://openai.github.io/openai-agents-python/sessions/sqlalchemy_session/)\\n        *   [Advanced SQLite Sessions](https://openai.github.io/openai-agents-python/sessions/advanced_sqlite_session/)\\n        *   [Encrypted Sessions](https://openai.github.io/openai-agents-python/sessions/encrypted_session/)\\n\\n    *   [Results](https://openai.github.io/openai-agents-python/results/)\\n    *   [Streaming](https://openai.github.io/openai-agents-python/streaming/)\\n    *   [REPL utility](https://openai.github.io/openai-agents-python/repl/)\\n    *   [Tools](https://openai.github.io/openai-agents-python/tools/)\\n    *   [Model context protocol (MCP)](https://openai.github.io/openai-agents-python/mcp/)\\n    *   [Handoffs](https://openai.github.io/openai-agents-python/handoffs/)\\n    *   [Tracing](https://openai.github.io/openai-agents-python/tracing/)\\n    *   [Context management](https://openai.github.io/openai-agents-python/context/)\\n    *   [Guardrails](https://openai.github.io/openai-agents-python/guardrails/)\\n    *   [Orchestrating multiple agents](https://openai.github.io/openai-agents-python/multi_agent/)\\n    *   [Usage](https://openai.github.io/openai-agents-python/usage/)\\n    *   - [x]  Models   Models  \\n        *   [Models](https://openai.github.io/openai-agents-python/models/)\\n        *   [Using any model via LiteLLM](https://openai.github.io/openai-agents-python/models/litellm/)\\n\\n    *   [Configuring the SDK](https://openai.github.io/openai-agents-python/config/)\\n    *   [Agent Visualization](https://openai.github.io/openai-agents-python/visualization/)\\n    *   [Release process/changelog](https://openai.github.io/openai-agents-python/release/)\\n    *   - [x]  Voice agents   Voice agents  \\n        *   [Quickstart](https://openai.github.io/openai-agents-python/voice/quickstart/)\\n        *   [Pipelines and workflows](https://openai.github.io/openai-agents-python/voice/pipeline/)\\n        *   [Tracing](https://openai.github.io/openai-agents-python/voice/tracing/)\\n\\n    *   - [x]  Realtime agents   Realtime agents  \\n        *   [Quickstart](https://openai.github.io/openai-agents-python/realtime/quickstart/)\\n        *   [Guide](https://openai.github.io/openai-agents-python/realtime/guide/)\\n\\n*   - [x]  API Reference   API Reference  \\n    *   - [x]  Agents   Agents  \\n        *   [Agents module](https://openai.github.io/openai-agents-python/ref/)\\n        *   [Agents](https://openai.github.io/openai-agents-python/ref/agent/)\\n        *   [Runner](https://openai.github.io/openai-agents-python/ref/run/)\\n        *   [Memory](https://openai.github.io/openai-agents-python/ref/memory/)\\n        *   [repl](https://openai.github.io/openai-agents-python/ref/repl/)\\n        *   [Tools](https://openai.github.io/openai-agents-python/ref/tool/)\\n        *   [Tool Context](https://openai.github.io/openai-agents-python/ref/tool_context/)\\n        *   [Results](https://openai.github.io/openai-agents-python/ref/result/)\\n        *   [Streaming events](https://openai.github.io/openai-agents-python/ref/stream_events/)\\n        *   [Handoffs](https://openai.github.io/openai-agents-python/ref/handoffs/)\\n        *   [Lifecycle](https://openai.github.io/openai-agents-python/ref/lifecycle/)\\n        *   [Items](https://openai.github.io/openai-agents-python/ref/items/)\\n        *   [Run context](https://openai.github.io/openai-agents-python/ref/run_context/)\\n        *   [Tool Context](https://openai.github.io/openai-agents-python/ref/tool_context/)\\n        *   [Usage](https://openai.github.io/openai-agents-python/ref/usage/)\\n        *   [Exceptions](https://openai.github.io/openai-agents-python/ref/exceptions/)\\n        *   [Guardrails](https://openai.github.io/openai-agents-python/ref/guardrail/)\\n        *   [Model settings](https://openai.github.io/openai-agents-python/ref/model_settings/)\\n        *   [Agent output](https://openai.github.io/openai-agents-python/ref/agent_output/)\\n        *   [Function schema](https://openai.github.io/openai-agents-python/ref/function_schema/)\\n        *   [Model interface](https://openai.github.io/openai-agents-python/ref/models/interface/)\\n        *   [OpenAI Chat Completions model](https://openai.github.io/openai-agents-python/ref/models/openai_chatcompletions/)\\n        *   [OpenAI Responses model](https://openai.github.io/openai-agents-python/ref/models/openai_responses/)\\n        *   [MCP Servers](https://openai.github.io/openai-agents-python/ref/mcp/server/)\\n        *   [MCP Util](https://openai.github.io/openai-agents-python/ref/mcp/util/)\\n\\n    *   - [x]  Tracing   Tracing  \\n        *   [Tracing module](https://openai.github.io/openai-agents-python/ref/tracing/)\\n        *   [Creating traces/spans](https://openai.github.io/openai-agents-python/ref/tracing/create/)\\n        *   [Traces](https://openai.github.io/openai-agents-python/ref/tracing/traces/)\\n        *   [Spans](https://openai.github.io/openai-agents-python/ref/tracing/spans/)\\n        *   [Processor interface](https://openai.github.io/openai-agents-python/ref/tracing/processor_interface/)\\n        *   [Processors](https://openai.github.io/openai-agents-python/ref/tracing/processors/)\\n        *   [Scope](https://openai.github.io/openai-agents-python/ref/tracing/scope/)\\n        *   [Setup](https://openai.github.io/openai-agents-python/ref/tracing/setup/)\\n        *   [Span data](https://openai.github.io/openai-agents-python/ref/tracing/span_data/)\\n        *   [Util](https://openai.github.io/openai-agents-python/ref/tracing/util/)\\n\\n    *   - [x]  Realtime   Realtime  \\n        *   [RealtimeAgent](https://openai.github.io/openai-agents-python/ref/realtime/agent/)\\n        *   [RealtimeRunner](https://openai.github.io/openai-agents-python/ref/realtime/runner/)\\n        *   [RealtimeSession](https://openai.github.io/openai-agents-python/ref/realtime/session/)\\n        *   [Realtime Events](https://openai.github.io/openai-agents-python/ref/realtime/events/)\\n        *   [Realtime Configuration](https://openai.github.io/openai-agents-python/ref/realtime/config/)\\n        *   [Model](https://openai.github.io/openai-agents-python/ref/realtime/model/)\\n\\n    *   - [x]  Voice   Voice  \\n        *   [Pipeline](https://openai.github.io/openai-agents-python/ref/voice/pipeline/)\\n        *   [Workflow](https://openai.github.io/openai-agents-python/ref/voice/workflow/)\\n        *   [Input](https://openai.github.io/openai-agents-python/ref/voice/input/)\\n        *   [Result](https://openai.github.io/openai-agents-python/ref/voice/result/)\\n        *   [Pipeline Config](https://openai.github.io/openai-agents-python/ref/voice/pipeline_config/)\\n        *   [Events](https://openai.github.io/openai-agents-python/ref/voice/events/)\\n        *   [Exceptions](https://openai.github.io/openai-agents-python/ref/voice/exceptions/)\\n        *   [Model](https://openai.github.io/openai-agents-python/ref/voice/model/)\\n        *   [Utils](https://openai.github.io/openai-agents-python/ref/voice/utils/)\\n        *   [OpenAIVoiceModelProvider](https://openai.github.io/openai-agents-python/ref/voice/models/openai_provider/)\\n        *   [OpenAI STT](https://openai.github.io/openai-agents-python/ref/voice/models/openai_stt/)\\n        *   [OpenAI TTS](https://openai.github.io/openai-agents-python/ref/voice/models/openai_tts/)\\n\\n    *   - [x]  Extensions   Extensions  \\n        *   [Handoff filters](https://openai.github.io/openai-agents-python/ref/extensions/handoff_filters/)\\n        *   [Handoff prompt](https://openai.github.io/openai-agents-python/ref/extensions/handoff_prompt/)\\n        *   [LiteLLM Models](https://openai.github.io/openai-agents-python/ref/extensions/litellm/)\\n        *   [SQLAlchemySession](https://openai.github.io/openai-agents-python/ref/extensions/memory/sqlalchemy_session/)\\n        *   [EncryptedSession](https://openai.github.io/openai-agents-python/ref/extensions/memory/encrypt_session/)\\n        *   [AdvancedSQLiteSession](https://openai.github.io/openai-agents-python/ref/extensions/memory/advanced_sqlite_session/)\\n\\n Table of contents  \\n*   [Why use the Agents SDK](https://openai.github.io/openai-agents-python/#why-use-the-agents-sdk)\\n*   [Installation](https://openai.github.io/openai-agents-python/#installation)\\n*   [Hello world example](https://openai.github.io/openai-agents-python/#hello-world-example)\\n\\nOpenAI Agents SDK\\n=================\\n\\nThe [OpenAI Agents SDK](https://github.com/openai/openai-agents-python) enables you to build agentic AI apps in a lightweight, easy-to-use package with very few abstractions. It\\'s a production-ready upgrade of our previous experimentation for agents, [Swarm](https://github.com/openai/swarm/tree/main). The Agents SDK has a very small set of primitives:\\n\\n*   **Agents**, which are LLMs equipped with instructions and tools\\n*   **Handoffs**, which allow agents to delegate to other agents for specific tasks\\n*   **Guardrails**, which enable validation of agent inputs and outputs\\n*   **Sessions**, which automatically maintains conversation history across agent runs\\n\\nIn combination with Python, these primitives are powerful enough to express complex relationships between tools and agents, and allow you to build real-world applications without a steep learning curve. In addition, the SDK comes with built-in **tracing** that lets you visualize and debug your agentic flows, as well as evaluate them and even fine-tune models for your application.\\n\\nWhy use the Agents SDK\\n----------------------\\n\\nThe SDK has two driving design principles:\\n\\n1.   Enough features to be worth using, but few enough primitives to make it quick to learn.\\n2.   Works great out of the box, but you can customize exactly what happens.\\n\\nHere are the main features of the SDK:\\n\\n*   Agent loop: Built-in agent loop that handles calling tools, sending results to the LLM, and looping until the LLM is done.\\n*   Python-first: Use built-in language features to orchestrate and chain agents, rather than needing to learn new abstractions.\\n*   Handoffs: A powerful feature to coordinate and delegate between multiple agents.\\n*   Guardrails: Run input validations and checks in parallel to your agents, breaking early if the checks fail.\\n*   Sessions: Automatic conversation history management across agent runs, eliminating manual state handling.\\n*   Function tools: Turn any Python function into a tool, with automatic schema generation and Pydantic-powered validation.\\n*   Tracing: Built-in tracing that lets you visualize, debug and monitor your workflows, as well as use the OpenAI suite of evaluation, fine-tuning and distillation tools.\\n\\nInstallation\\n------------\\n\\n```\\npip install openai-agents\\n```\\n\\nHello world example\\n-------------------\\n\\n```\\nfrom agents import Agent, Runner\\n\\nagent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\\n\\nresult = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\\nprint(result.final_output)\\n\\n# Code within the code,\\n# Functions calling themselves,\\n# Infinite loop\\'s dance.\\n```\\n\\n(_If running this, ensure you set the `OPENAI\\\\_API\\\\_KEY` environment variable_)\\n\\n```\\nexport OPENAI_API_KEY=sk-...\\n```\\n', type='tool_call_output_item'),\n",
       " MessageOutputItem(agent=Agent(name='web_agent', handoff_description=None, tools=[FunctionTool(name='fetch_url', description='', params_json_schema={'properties': {'url': {'title': 'Url', 'type': 'string'}}, 'required': ['url'], 'title': 'fetch_url_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x0000024893DBDE40>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)], mcp_servers=[], mcp_config={}, instructions=\"you're a helpful assistant\", prompt=None, handoffs=[], model='gpt-4o-mini', model_settings=ModelSettings(temperature=None, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=None, truncation=None, max_tokens=None, reasoning=None, verbosity=None, metadata=None, store=None, include_usage=None, response_include=None, top_logprobs=None, extra_query=None, extra_body=None, extra_headers=None, extra_args=None), input_guardrails=[], output_guardrails=[], output_type=None, hooks=None, tool_use_behavior='run_llm_again', reset_tool_choice=True), raw_item=ResponseOutputMessage(id='msg_031eeed2da53f7110068f19284f0948193863bbff7c0f36719', content=[ResponseOutputText(annotations=[], text='The page is about the **OpenAI Agents SDK**, a toolkit designed for building intelligent applications using AI agents. It provides users with a lightweight, easy-to-use framework that includes essential components like agents, handoffs, guardrails, and sessions. \\n\\n### Key Features:\\n- **Agent Loop**: Manages calling tools and handling results automatically.\\n- **Python First**: Utilizes Python\\'s language features for orchestration.\\n- **Handoffs**: Allows agents to delegate tasks to one another.\\n- **Guardrails**: Implements input and output validation.\\n- **Sessions**: Manages conversation history seamlessly.\\n- **Function Tools**: Converts Python functions into actionable tools.\\n- **Tracing**: Visualizes and debugs workflows.\\n\\n### Getting Started:\\nInstallation is straightforward with a simple pip command. The page includes a \"Hello World\" example to showcase basic functionality.\\n\\n### Documentation Links:\\nIt also provides extensive documentation covering installation, examples, and detailed API references for various features of the SDK.\\n\\nFor more details, you can explore the [OpenAI Agents SDK GitHub page](https://github.com/openai/openai-agents-python).', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), type='message_output_item')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.new_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec068a0e-4773-4edb-be29-7a4ed6e1b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import OpenAIAgentsSDKRunner\n",
    "\n",
    "chat_interface = IPythonChatInterface()\n",
    "\n",
    "runner = OpenAIAgentsSDKRunner(\n",
    "    chat_interface=chat_interface,\n",
    "    agent=web_agent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5760e01f-43c6-434b-82a6-51eb6c2cbf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: whats is this page about? https://openai.github.io/openai-agents-python/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>fetch_url({\"url\":\"https://openai.github.io/openai-agents-...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"url\":\"https://openai.github.io/openai-agents-python/\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>Title: OpenAI Agents SDK\n",
       "\n",
       "URL Source: https://openai.github.io/openai-agents-python/\n",
       "\n",
       "Published Time: Fri, 17 Oct 2025 00:27:03 GMT\n",
       "\n",
       "Markdown Content:\n",
       "OpenAI Agents SDK\n",
       "\n",
       "===============\n",
       "- [x] - [x] \n",
       "\n",
       "[Skip to content](https://openai.github.io/openai-agents-python/#openai-agents-sdk)\n",
       "\n",
       "[![Image 1: logo](https://openai.github.io/openai-agents-python/assets/logo.svg)](https://openai.github.io/openai-agents-python/ \"OpenAI Agents SDK\")\n",
       "\n",
       " OpenAI Agents SDK \n",
       "\n",
       " Intro \n",
       "\n",
       "*   [English](https://openai.github.io/openai-agents-python/)\n",
       "*   [日本語](https://openai.github.io/openai-agents-python/ja/)\n",
       "*   [한국어](https://openai.github.io/openai-agents-python/ko/)\n",
       "*   [简体中文](https://openai.github.io/openai-agents-python/zh/)\n",
       "\n",
       " Initializing search \n",
       "\n",
       "[openai-agents-python](https://github.com/openai/openai-agents-python \"Go to repository\")\n",
       "\n",
       "[![Image 2: logo](https://openai.github.io/openai-agents-python/assets/logo.svg)](https://openai.github.io/openai-agents-python/ \"OpenAI Agents SDK\") OpenAI Agents SDK  \n",
       "\n",
       "[openai-agents-python](https://github.com/openai/openai-agents-python \"Go to repository\")\n",
       "\n",
       "*   - [x]  Intro  [Intro](https://openai.github.io/openai-agents-python/) Table of contents  \n",
       "    *   [Why use the Agents SDK](https://openai.github.io/openai-agents-python/#why-use-the-agents-sdk)\n",
       "    *   [Installation](https://openai.github.io/openai-agents-python/#installation)\n",
       "    *   [Hello world example](https://openai.github.io/openai-agents-python/#hello-world-example)\n",
       "\n",
       "*   [Quickstart](https://openai.github.io/openai-agents-python/quickstart/)\n",
       "*   [Examples](https://openai.github.io/openai-agents-python/examples/)\n",
       "*   - [x]  Documentation   Documentation  \n",
       "    *   [Agents](https://openai.github.io/openai-agents-python/agents/)\n",
       "    *   [Running agents](https://openai.github.io/openai-agents-python/running_agents/)\n",
       "    *   - [x]  Sessions   Sessions  \n",
       "        *   [Sessions](https://openai.github.io/openai-agents-python/sessions/)\n",
       "        *   [SQLAlchemy Sessions](https://openai.github.io/openai-agents-python/sessions/sqlalchemy_session/)\n",
       "        *   [Advanced SQLite Sessions](https://openai.github.io/openai-agents-python/sessions/advanced_sqlite_session/)\n",
       "        *   [Encrypted Sessions](https://openai.github.io/openai-agents-python/sessions/encrypted_session/)\n",
       "\n",
       "    *   [Results](https://openai.github.io/openai-agents-python/results/)\n",
       "    *   [Streaming](https://openai.github.io/openai-agents-python/streaming/)\n",
       "    *   [REPL utility](https://openai.github.io/openai-agents-python/repl/)\n",
       "    *   [Tools](https://openai.github.io/openai-agents-python/tools/)\n",
       "    *   [Model context protocol (MCP)](https://openai.github.io/openai-agents-python/mcp/)\n",
       "    *   [Handoffs](https://openai.github.io/openai-agents-python/handoffs/)\n",
       "    *   [Tracing](https://openai.github.io/openai-agents-python/tracing/)\n",
       "    *   [Context management](https://openai.github.io/openai-agents-python/context/)\n",
       "    *   [Guardrails](https://openai.github.io/openai-agents-python/guardrails/)\n",
       "    *   [Orchestrating multiple agents](https://openai.github.io/openai-agents-python/multi_agent/)\n",
       "    *   [Usage](https://openai.github.io/openai-agents-python/usage/)\n",
       "    *   - [x]  Models   Models  \n",
       "        *   [Models](https://openai.github.io/openai-agents-python/models/)\n",
       "        *   [Using any model via LiteLLM](https://openai.github.io/openai-agents-python/models/litellm/)\n",
       "\n",
       "    *   [Configuring the SDK](https://openai.github.io/openai-agents-python/config/)\n",
       "    *   [Agent Visualization](https://openai.github.io/openai-agents-python/visualization/)\n",
       "    *   [Release process/changelog](https://openai.github.io/openai-agents-python/release/)\n",
       "    *   - [x]  Voice agents   Voice agents  \n",
       "        *   [Quickstart](https://openai.github.io/openai-agents-python/voice/quickstart/)\n",
       "        *   [Pipelines and workflows](https://openai.github.io/openai-agents-python/voice/pipeline/)\n",
       "        *   [Tracing](https://openai.github.io/openai-agents-python/voice/tracing/)\n",
       "\n",
       "    *   - [x]  Realtime agents   Realtime agents  \n",
       "        *   [Quickstart](https://openai.github.io/openai-agents-python/realtime/quickstart/)\n",
       "        *   [Guide](https://openai.github.io/openai-agents-python/realtime/guide/)\n",
       "\n",
       "*   - [x]  API Reference   API Reference  \n",
       "    *   - [x]  Agents   Agents  \n",
       "        *   [Agents module](https://openai.github.io/openai-agents-python/ref/)\n",
       "        *   [Agents](https://openai.github.io/openai-agents-python/ref/agent/)\n",
       "        *   [Runner](https://openai.github.io/openai-agents-python/ref/run/)\n",
       "        *   [Memory](https://openai.github.io/openai-agents-python/ref/memory/)\n",
       "        *   [repl](https://openai.github.io/openai-agents-python/ref/repl/)\n",
       "        *   [Tools](https://openai.github.io/openai-agents-python/ref/tool/)\n",
       "        *   [Tool Context](https://openai.github.io/openai-agents-python/ref/tool_context/)\n",
       "        *   [Results](https://openai.github.io/openai-agents-python/ref/result/)\n",
       "        *   [Streaming events](https://openai.github.io/openai-agents-python/ref/stream_events/)\n",
       "        *   [Handoffs](https://openai.github.io/openai-agents-python/ref/handoffs/)\n",
       "        *   [Lifecycle](https://openai.github.io/openai-agents-python/ref/lifecycle/)\n",
       "        *   [Items](https://openai.github.io/openai-agents-python/ref/items/)\n",
       "        *   [Run context](https://openai.github.io/openai-agents-python/ref/run_context/)\n",
       "        *   [Tool Context](https://openai.github.io/openai-agents-python/ref/tool_context/)\n",
       "        *   [Usage](https://openai.github.io/openai-agents-python/ref/usage/)\n",
       "        *   [Exceptions](https://openai.github.io/openai-agents-python/ref/exceptions/)\n",
       "        *   [Guardrails](https://openai.github.io/openai-agents-python/ref/guardrail/)\n",
       "        *   [Model settings](https://openai.github.io/openai-agents-python/ref/model_settings/)\n",
       "        *   [Agent output](https://openai.github.io/openai-agents-python/ref/agent_output/)\n",
       "        *   [Function schema](https://openai.github.io/openai-agents-python/ref/function_schema/)\n",
       "        *   [Model interface](https://openai.github.io/openai-agents-python/ref/models/interface/)\n",
       "        *   [OpenAI Chat Completions model](https://openai.github.io/openai-agents-python/ref/models/openai_chatcompletions/)\n",
       "        *   [OpenAI Responses model](https://openai.github.io/openai-agents-python/ref/models/openai_responses/)\n",
       "        *   [MCP Servers](https://openai.github.io/openai-agents-python/ref/mcp/server/)\n",
       "        *   [MCP Util](https://openai.github.io/openai-agents-python/ref/mcp/util/)\n",
       "\n",
       "    *   - [x]  Tracing   Tracing  \n",
       "        *   [Tracing module](https://openai.github.io/openai-agents-python/ref/tracing/)\n",
       "        *   [Creating traces/spans](https://openai.github.io/openai-agents-python/ref/tracing/create/)\n",
       "        *   [Traces](https://openai.github.io/openai-agents-python/ref/tracing/traces/)\n",
       "        *   [Spans](https://openai.github.io/openai-agents-python/ref/tracing/spans/)\n",
       "        *   [Processor interface](https://openai.github.io/openai-agents-python/ref/tracing/processor_interface/)\n",
       "        *   [Processors](https://openai.github.io/openai-agents-python/ref/tracing/processors/)\n",
       "        *   [Scope](https://openai.github.io/openai-agents-python/ref/tracing/scope/)\n",
       "        *   [Setup](https://openai.github.io/openai-agents-python/ref/tracing/setup/)\n",
       "        *   [Span data](https://openai.github.io/openai-agents-python/ref/tracing/span_data/)\n",
       "        *   [Util](https://openai.github.io/openai-agents-python/ref/tracing/util/)\n",
       "\n",
       "    *   - [x]  Realtime   Realtime  \n",
       "        *   [RealtimeAgent](https://openai.github.io/openai-agents-python/ref/realtime/agent/)\n",
       "        *   [RealtimeRunner](https://openai.github.io/openai-agents-python/ref/realtime/runner/)\n",
       "        *   [RealtimeSession](https://openai.github.io/openai-agents-python/ref/realtime/session/)\n",
       "        *   [Realtime Events](https://openai.github.io/openai-agents-python/ref/realtime/events/)\n",
       "        *   [Realtime Configuration](https://openai.github.io/openai-agents-python/ref/realtime/config/)\n",
       "        *   [Model](https://openai.github.io/openai-agents-python/ref/realtime/model/)\n",
       "\n",
       "    *   - [x]  Voice   Voice  \n",
       "        *   [Pipeline](https://openai.github.io/openai-agents-python/ref/voice/pipeline/)\n",
       "        *   [Workflow](https://openai.github.io/openai-agents-python/ref/voice/workflow/)\n",
       "        *   [Input](https://openai.github.io/openai-agents-python/ref/voice/input/)\n",
       "        *   [Result](https://openai.github.io/openai-agents-python/ref/voice/result/)\n",
       "        *   [Pipeline Config](https://openai.github.io/openai-agents-python/ref/voice/pipeline_config/)\n",
       "        *   [Events](https://openai.github.io/openai-agents-python/ref/voice/events/)\n",
       "        *   [Exceptions](https://openai.github.io/openai-agents-python/ref/voice/exceptions/)\n",
       "        *   [Model](https://openai.github.io/openai-agents-python/ref/voice/model/)\n",
       "        *   [Utils](https://openai.github.io/openai-agents-python/ref/voice/utils/)\n",
       "        *   [OpenAIVoiceModelProvider](https://openai.github.io/openai-agents-python/ref/voice/models/openai_provider/)\n",
       "        *   [OpenAI STT](https://openai.github.io/openai-agents-python/ref/voice/models/openai_stt/)\n",
       "        *   [OpenAI TTS](https://openai.github.io/openai-agents-python/ref/voice/models/openai_tts/)\n",
       "\n",
       "    *   - [x]  Extensions   Extensions  \n",
       "        *   [Handoff filters](https://openai.github.io/openai-agents-python/ref/extensions/handoff_filters/)\n",
       "        *   [Handoff prompt](https://openai.github.io/openai-agents-python/ref/extensions/handoff_prompt/)\n",
       "        *   [LiteLLM Models](https://openai.github.io/openai-agents-python/ref/extensions/litellm/)\n",
       "        *   [SQLAlchemySession](https://openai.github.io/openai-agents-python/ref/extensions/memory/sqlalchemy_session/)\n",
       "        *   [EncryptedSession](https://openai.github.io/openai-agents-python/ref/extensions/memory/encrypt_session/)\n",
       "        *   [AdvancedSQLiteSession](https://openai.github.io/openai-agents-python/ref/extensions/memory/advanced_sqlite_session/)\n",
       "\n",
       " Table of contents  \n",
       "*   [Why use the Agents SDK](https://openai.github.io/openai-agents-python/#why-use-the-agents-sdk)\n",
       "*   [Installation](https://openai.github.io/openai-agents-python/#installation)\n",
       "*   [Hello world example](https://openai.github.io/openai-agents-python/#hello-world-example)\n",
       "\n",
       "OpenAI Agents SDK\n",
       "=================\n",
       "\n",
       "The [OpenAI Agents SDK](https://github.com/openai/openai-agents-python) enables you to build agentic AI apps in a lightweight, easy-to-use package with very few abstractions. It's a production-ready upgrade of our previous experimentation for agents, [Swarm](https://github.com/openai/swarm/tree/main). The Agents SDK has a very small set of primitives:\n",
       "\n",
       "*   **Agents**, which are LLMs equipped with instructions and tools\n",
       "*   **Handoffs**, which allow agents to delegate to other agents for specific tasks\n",
       "*   **Guardrails**, which enable validation of agent inputs and outputs\n",
       "*   **Sessions**, which automatically maintains conversation history across agent runs\n",
       "\n",
       "In combination with Python, these primitives are powerful enough to express complex relationships between tools and agents, and allow you to build real-world applications without a steep learning curve. In addition, the SDK comes with built-in **tracing** that lets you visualize and debug your agentic flows, as well as evaluate them and even fine-tune models for your application.\n",
       "\n",
       "Why use the Agents SDK\n",
       "----------------------\n",
       "\n",
       "The SDK has two driving design principles:\n",
       "\n",
       "1.   Enough features to be worth using, but few enough primitives to make it quick to learn.\n",
       "2.   Works great out of the box, but you can customize exactly what happens.\n",
       "\n",
       "Here are the main features of the SDK:\n",
       "\n",
       "*   Agent loop: Built-in agent loop that handles calling tools, sending results to the LLM, and looping until the LLM is done.\n",
       "*   Python-first: Use built-in language features to orchestrate and chain agents, rather than needing to learn new abstractions.\n",
       "*   Handoffs: A powerful feature to coordinate and delegate between multiple agents.\n",
       "*   Guardrails: Run input validations and checks in parallel to your agents, breaking early if the checks fail.\n",
       "*   Sessions: Automatic conversation history management across agent runs, eliminating manual state handling.\n",
       "*   Function tools: Turn any Python function into a tool, with automatic schema generation and Pydantic-powered validation.\n",
       "*   Tracing: Built-in tracing that lets you visualize, debug and monitor your workflows, as well as use the OpenAI suite of evaluation, fine-tuning and distillation tools.\n",
       "\n",
       "Installation\n",
       "------------\n",
       "\n",
       "```\n",
       "pip install openai-agents\n",
       "```\n",
       "\n",
       "Hello world example\n",
       "-------------------\n",
       "\n",
       "```\n",
       "from agents import Agent, Runner\n",
       "\n",
       "agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\")\n",
       "\n",
       "result = Runner.run_sync(agent, \"Write a haiku about recursion in programming.\")\n",
       "print(result.final_output)\n",
       "\n",
       "# Code within the code,\n",
       "# Functions calling themselves,\n",
       "# Infinite loop's dance.\n",
       "```\n",
       "\n",
       "(_If running this, ensure you set the `OPENAI\\_API\\_KEY` environment variable_)\n",
       "\n",
       "```\n",
       "export OPENAI_API_KEY=sk-...\n",
       "```\n",
       "</pre>\n",
       "            </div>\n",
       "\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The page is about the <strong>OpenAI Agents SDK</strong>, which is designed to help developers build AI applications with agent capabilities. Here's a brief overview of the key elements:</p>\n",
       "<h3>Overview:</h3>\n",
       "<ul>\n",
       "<li><strong>Purpose</strong>: The SDK provides a lightweight way to create AI agents that can perform tasks using language models (LLMs), with built-in management for conversation history, tool usage, and debugging.</li>\n",
       "<li><strong>Key Features</strong>:<ul>\n",
       "<li><strong>Agents</strong>: AI models with specific instructions and the ability to use tools.</li>\n",
       "<li><strong>Handoffs</strong>: Allow agents to delegate tasks to other agents.</li>\n",
       "<li><strong>Guardrails</strong>: Validate input and output from the agents.</li>\n",
       "<li><strong>Sessions</strong>: Automatically maintain conversation context.</li>\n",
       "</ul>\n",
       "</li>\n",
       "</ul>\n",
       "<h3>Design Principles:</h3>\n",
       "<ol>\n",
       "<li><strong>User-friendly</strong>: Designed to be easy to learn while providing sufficient features.</li>\n",
       "<li><strong>Customizable</strong>: Works well out of the box, but also allows for extensive customization.</li>\n",
       "</ol>\n",
       "<h3>Installation:</h3>\n",
       "<p>You can install it using:</p>\n",
       "<pre><code class=\"language-bash\">pip install openai-agents\n",
       "</code></pre>\n",
       "<h3>Example Code:</h3>\n",
       "<p>A simple example shows how to create an agent and run a task:</p>\n",
       "<pre><code class=\"language-python\">from agents import Agent, Runner\n",
       "\n",
       "agent = Agent(name=&quot;Assistant&quot;, instructions=&quot;You are a helpful assistant&quot;)\n",
       "result = Runner.run_sync(agent, &quot;Write a haiku about recursion in programming.&quot;)\n",
       "print(result.final_output)\n",
       "</code></pre>\n",
       "<p>Overall, the page serves as a comprehensive guide for using the OpenAI Agents SDK, including getting started, key functionalities, and use cases.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: what are agents?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>In the context of the OpenAI Agents SDK, <strong>agents</strong> are AI models equipped with specific instructions and tools that allow them to perform tasks autonomously. Here are some key aspects of agents:</p>\n",
       "<ol>\n",
       "<li><p><strong>Functionality</strong>: Agents can process input, make decisions, and generate responses based on their instructions. They leverage language models to understand and respond to queries.</p>\n",
       "</li>\n",
       "<li><p><strong>Task Management</strong>: They can delegate tasks to other agents through a system of <strong>handoffs</strong>, allowing for complex workflows that involve multiple agents working together.</p>\n",
       "</li>\n",
       "<li><p><strong>Tools</strong>: Agents can utilize various tools (like functions defined in code) to enhance their capabilities, such as performing calculations, querying databases, or interacting with APIs.</p>\n",
       "</li>\n",
       "<li><p><strong>Context Handling</strong>: They automatically manage conversation history and context across interactions, ensuring continuity and coherence in dialogues.</p>\n",
       "</li>\n",
       "<li><p><strong>Guardrails</strong>: Agents are equipped with validation mechanisms to ensure the inputs and outputs adhere to defined standards, which helps in maintaining quality and safety.</p>\n",
       "</li>\n",
       "</ol>\n",
       "<p>Overall, agents in this SDK are designed to facilitate the creation of intelligent, automated applications by providing a structured way to manage AI interactions and workflows.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "await runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86b2b69c-dfb5-4840-a68a-75cf887b8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Youtube Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e7852a0-2292-417b-a385-6b42a8e5fd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "def format_timestamp(seconds: float) -> str:\n",
    "    \"\"\"Convert seconds to H:MM:SS if > 1 hour, else M:SS\"\"\"\n",
    "    total_seconds = int(seconds)\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, secs = divmod(remainder, 60)\n",
    "\n",
    "    if hours > 0:\n",
    "        return f\"{hours}:{minutes:02}:{secs:02}\"\n",
    "    else:\n",
    "        return f\"{minutes}:{secs:02}\"\n",
    "\n",
    "\n",
    "def make_subtitles(transcript) -> str:\n",
    "    lines = []\n",
    "\n",
    "    for entry in transcript:\n",
    "        ts = format_timestamp(entry.start)\n",
    "        text = entry.text.replace('\\n', ' ')\n",
    "        lines.append(ts + ' ' + text)\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "\n",
    "def fetch_transcript_raw(video_id):\n",
    "    ytt_api = YouTubeTranscriptApi()\n",
    "    transcript = ytt_api.fetch(video_id)\n",
    "    return transcript\n",
    "\n",
    "\n",
    "def fetch_transcript_text(video_id):\n",
    "    transcript = fetch_transcript_raw(video_id)\n",
    "    subtitles = make_subtitles(transcript)\n",
    "    return subtitles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48373418-d4a3-4307-a9f8-5c5ee6e468ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def fetch_transcript_cached(video_id):\n",
    "    cache_dir = Path(\"../data_cache/youtube_videos\")\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cache_file = cache_dir / f\"{video_id}.txt\"\n",
    "\n",
    "    if cache_file.exists():\n",
    "        return cache_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "    subtitles = fetch_transcript_text(video_id)\n",
    "    cache_file.write_text(subtitles, encoding=\"utf-8\")\n",
    "\n",
    "    return subtitles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8c7cd8ae-b560-4a8e-9cad-5a887e39c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00 Hey everyone, welcome to our event. This\n",
      "0:02 event is brought to you by data talks\n",
      "0:03 club which is a community of people who\n",
      "0:05 love data. We have weekly events today.\n",
      "0:08 Uh this is one of such events. Um if you\n",
      "0:11 want to find out more about the events\n",
      "0:13 we have, there is a link in the\n",
      "0:14 description. Um so click on that link,\n",
      "0:16 check it out right now. We actually have\n",
      "0:19 quite a few events in our pipeline, but\n",
      "0:21 we need to put them on the website. Uh\n",
      "0:24 but keep a\n"
     ]
    }
   ],
   "source": [
    "subtitles = fetch_transcript_cached('vK_SxyqIfwk')\n",
    "print(subtitles[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e6efea6-f307-4f5c-815f-d2c5e42d76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_youtube_transcript(video_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the transcript of a YouTube video and converts it into a subtitle-formatted string.\n",
    "\n",
    "    Args:\n",
    "        video_id (str): The unique YouTube video ID.\n",
    "\n",
    "    Returns:\n",
    "        str: The subtitles generated from the video's transcript.\n",
    "    \"\"\"\n",
    "    return fetch_transcript_cached(video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4228ba0-ed37-48d1-b01a-368373861aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_instructions = \"\"\"\n",
    "You're helpful assistant that helps answer user qusetions\n",
    "about Youtube videos\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6cb2996-2061-4ab0-a544-7827512c010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_agent = Agent(\n",
    "    name='youtube_agent',\n",
    "    instructions=summary_instructions,\n",
    "    tools=[function_tool(fetch_youtube_transcript)],\n",
    "    model='gpt-4o-mini'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f823d464-c059-41b7-a9e7-2d9232fef504",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = OpenAIAgentsSDKRunner(\n",
    "    chat_interface=chat_interface,\n",
    "    agent=web_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c7538e-e27f-4f77-94f1-c7587d7a0a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Whats this video about https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>fetch_url({\"url\":\"https://www.youtube.com/watch?v=vK_Sxyq...)</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>{\"url\":\"https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s\"}</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>Title: Lessons from Applied AI: Tesla, Waymo, and Beyond - Aishwarya Jadhav\n",
       "\n",
       "URL Source: https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s\n",
       "\n",
       "Markdown Content:\n",
       "Lessons from Applied AI: Tesla, Waymo, and Beyond - Aishwarya Jadhav - YouTube\n",
       "\n",
       "===============\n",
       "\n",
       " Back [![Image 1](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)](https://www.youtube.com/ \"YouTube Home\")\n",
       "\n",
       "Skip navigation\n",
       "\n",
       " Search \n",
       "\n",
       " Search with your voice \n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "[Sign in](https://accounts.google.com/ServiceLogin?service=youtube&uilel=3&passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Faction_handle_signin%3Dtrue%26app%3Ddesktop%26hl%3Den%26next%3Dhttps%253A%252F%252Fwww.youtube.com%252Fwatch%253Fv%253DvK_SxyqIfwk%2526t%253D172s&hl=en&ec=65620)\n",
       "\n",
       "[![Image 2](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)](https://www.youtube.com/ \"YouTube Home\")\n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "[Lessons from Applied AI: Tesla, Waymo, and Beyond - Aishwarya Jadhav](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "Search\n",
       "\n",
       "Watch later\n",
       "\n",
       "Share\n",
       "\n",
       "Copy link\n",
       "\n",
       "Info\n",
       "\n",
       "Shopping\n",
       "\n",
       "Tap to unmute\n",
       "\n",
       "2x\n",
       "\n",
       "[![Image 3](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "If playback doesn't begin shortly, try restarting your device.\n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "[![Image 4](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "•\n",
       "\n",
       "You're signed out\n",
       "\n",
       "Videos you watch may be added to the TV's watch history and influence TV recommendations. To avoid this, cancel and sign in to YouTube on your computer.\n",
       "\n",
       "Cancel Confirm\n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "Share\n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s \"Share link\")- [x] Include playlist \n",
       "\n",
       "An error occurred while retrieving sharing information. Please try again later.\n",
       "\n",
       "![Image 5](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "0:00\n",
       "\n",
       "[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)[](https://www.youtube.com/watch?v=EkuVqdj8O6E \"Next (SHIFT+n)\")\n",
       "\n",
       "0:00 / 0:00\n",
       "\n",
       "•Watch full video Live\n",
       "\n",
       "•\n",
       "\n",
       "•\n",
       "\n",
       "Sign in to confirm you’re not a bot This helps protect our community. [Learn more](https://support.google.com/youtube/answer/3037019#zippy=%2Ccheck-that-youre-signed-into-youtube)\n",
       "\n",
       "[Sign in](https://accounts.google.com/ServiceLogin?service=youtube&uilel=3&passive=true&continue=https%3A%2F%2Fwww.youtube.com%2Fsignin%3Faction_handle_signin%3Dtrue%26app%3Ddesktop%26hl%3Den%26next%3D%252Fwatch%253Fv%253DvK_SxyqIfwk%2526t%253D172s&hl=en)\n",
       "\n",
       "Lessons from Applied AI: Tesla, Waymo, and Beyond - Aishwarya Jadhav\n",
       "====================================================================\n",
       "\n",
       "[![Image 6](https://yt3.ggpht.com/Io8amNVLsli8xrPhIGrgDSfWhrRtSLMNZKQAYzE-dtTl9of1wKbxAfN4m-6Pq3EGwe8qU0tN=s48-c-k-c0x00ffffff-no-rj)](https://www.youtube.com/@DataTalksClub)\n",
       "\n",
       "[DataTalksClub ⬛](https://www.youtube.com/@DataTalksClub)\n",
       "\n",
       " DataTalksClub ⬛ \n",
       "\n",
       "66.7K subscribers\n",
       "\n",
       "Subscribe\n",
       "\n",
       "Subscribed\n",
       "\n",
       "23\n",
       "\n",
       "Share\n",
       "\n",
       "Download\n",
       "\n",
       " Download \n",
       "\n",
       "651 views Streamed 2 weeks ago[DataTalks.Club Podcast](https://www.youtube.com/playlist?list=PL3MmuxUbc_hK60wsCyvrEK2RjQsUi4Oa_)\n",
       "\n",
       " 651 views • Streamed live on Sep 29, 2025 • DataTalks.Club Podcast \n",
       "\n",
       "Show less \n",
       "\n",
       "In this episode, we talked with Aishwarya Jadhav, a machine learning engineer whose career has spanned Morgan Stanley, Tesla, and now Waymo. Aishwarya shares her journey from big data in finance to applied AI in self-driving, gesture understanding, and computer vision. She discus…...more \n",
       "\n",
       "...more \n",
       "\n",
       "Key moments\n",
       "\n",
       "View all\n",
       "-----------------------\n",
       "\n",
       "[![Image 7](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Aishwarya’s career journey from finance to self-driving AI #### Aishwarya’s career journey from finance to self-driving AI 0:51](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=51s)\n",
       "\n",
       "[#### Aishwarya’s career journey from finance to self-driving AI](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=51s)\n",
       "\n",
       "0:51\n",
       "\n",
       "[![Image 8](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Building AI guide dog for the visually impaired #### Building AI guide dog for the visually impaired 5:45](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=345s)\n",
       "\n",
       "[#### Building AI guide dog for the visually impaired](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=345s)\n",
       "\n",
       "5:45\n",
       "\n",
       "[![Image 9](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Exploring LiDAR, radar, and Tesla’s camera-based approach #### Exploring LiDAR, radar, and Tesla’s camera-based approach 12:03](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=723s&pp=0gcJCdcCDuyUWbzu)\n",
       "\n",
       "[#### Exploring LiDAR, radar, and Tesla’s camera-based approach](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=723s&pp=0gcJCdcCDuyUWbzu)\n",
       "\n",
       "12:03\n",
       "\n",
       "[![Image 10](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Trust, regulation, and challenges in self-driving adoption #### Trust, regulation, and challenges in self-driving adoption 16:24](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=984s&pp=0gcJCdcCDuyUWbzu)\n",
       "\n",
       "[#### Trust, regulation, and challenges in self-driving adoption](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=984s&pp=0gcJCdcCDuyUWbzu)\n",
       "\n",
       "16:24\n",
       "\n",
       "[![Image 11](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Waymo, ride-hailing, and gesture recognition for traffic control #### Waymo, ride-hailing, and gesture recognition for traffic control 19:39](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1179s)\n",
       "\n",
       "[#### Waymo, ride-hailing, and gesture recognition for traffic control](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1179s)\n",
       "\n",
       "19:39\n",
       "\n",
       "[![Image 12](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Malaria mapping in Africa and AI for social good #### Malaria mapping in Africa and AI for social good 24:18](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1458s)\n",
       "\n",
       "[#### Malaria mapping in Africa and AI for social good](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1458s)\n",
       "\n",
       "24:18\n",
       "\n",
       "[![Image 13](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Deployment, safety, and testing in self-driving systems #### Deployment, safety, and testing in self-driving systems 29:40](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1780s)\n",
       "\n",
       "[#### Deployment, safety, and testing in self-driving systems](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1780s)\n",
       "\n",
       "29:40\n",
       "\n",
       "[![Image 14](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Transition from NLP to computer vision and deep learning #### Transition from NLP to computer vision and deep learning 37:00](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=2220s)\n",
       "\n",
       "[#### Transition from NLP to computer vision and deep learning](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=2220s)\n",
       "\n",
       "37:00\n",
       "\n",
       "Explore the podcast\n",
       "\n",
       "[![Image 15](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)191 episodes 191 episodes](https://www.youtube.com/playlist?list=PL3MmuxUbc_hK60wsCyvrEK2RjQsUi4Oa_)\n",
       "\n",
       "DataTalks.Club Podcast\n",
       "\n",
       "DataTalksClub ⬛\n",
       "\n",
       "[![Image 16](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) Podcasts](https://www.youtube.com/podcasts)\n",
       "\n",
       "Transcript\n",
       "\n",
       "Follow along using the transcript.\n",
       "\n",
       "Show transcript\n",
       "\n",
       "[![Image 17](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) ### DataTalksClub ⬛ 66.7K subscribers](https://www.youtube.com/@DataTalksClub)\n",
       "\n",
       "[Videos](https://www.youtube.com/channel/UCDvErgK0j5ur3aLgn6U-LqQ/videos)\n",
       "\n",
       "[About](https://www.youtube.com/channel/UCDvErgK0j5ur3aLgn6U-LqQ/about)\n",
       "\n",
       "[Videos](https://www.youtube.com/channel/UCDvErgK0j5ur3aLgn6U-LqQ/videos)[About](https://www.youtube.com/channel/UCDvErgK0j5ur3aLgn6U-LqQ/about)[![Image 18](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) Twitter](https://www.youtube.com/redirect?event=Watch_SD_EP&redir_token=QUFFLUhqa0FHdFRxZk1kMWVXQ1g3ZG82OWdxUWp0Y202d3xBQ3Jtc0tsX0pEa3psY3dHZkhvRkstdEd1cG12cm1KQmpnWWhMNDFQWWgwaGlWVTl2OFJxazd5enV6NENUdHlLaVBLWkpIUGM0MTAwNXgwZUdHZ2pianh4UnJmM2VTemktMG1weTJkb3pkVjBQdm1haGdSNzJ0aw&q=https%3A%2F%2Ftwitter.com%2FDataTalksClub)[![Image 19](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) LinkedIn](https://www.youtube.com/redirect?event=Watch_SD_EP&redir_token=QUFFLUhqbDFuQ05RQzltSmhvdTIwLXFRbGdpbTBLZDdEUXxBQ3Jtc0tuQUZmVkhueXVhbDVmOURDcWxLTElrbEQtQzR6ZXJScjY2bGUzckJoSndRbktoSmVCZlVwRzJUOGhsRDVycFowUG1VS2RqM2ZIOW5IRndvN2d2aU1WSlV2QjhJNlphQV9SRjZYaTVESWNLRVhXR1V3Zw&q=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Fdatatalks-club%2F)\n",
       "\n",
       "Show less \n",
       "\n",
       "[](https://www.youtube.com/playlist?list=PL3MmuxUbc_hK60wsCyvrEK2RjQsUi4Oa_)[DataTalks.Club Podcast](https://www.youtube.com/playlist?list=PL3MmuxUbc_hK60wsCyvrEK2RjQsUi4Oa_)\n",
       "Lessons from Applied AI: Tesla, Waymo, and Beyond - Aishwarya Jadhav\n",
       "====================================================================\n",
       "\n",
       "651 views 651 views\n",
       "\n",
       "Streamed live on Sep 29, 2025\n",
       "\n",
       "23\n",
       "\n",
       "Share\n",
       "\n",
       "Download\n",
       "\n",
       " Download \n",
       "\n",
       "Save\n",
       "\n",
       "1 Comment\n",
       "---------\n",
       "\n",
       " Sort comments \n",
       "\n",
       "Sort by\n",
       "\n",
       "[Top comments](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)[Newest first](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "![Image 20: Default profile photo](https://yt3.ggpht.com/a/default-user=s48-c-k-c0x00ffffff-no-rj)\n",
       "\n",
       "Add a comment...\n",
       "\n",
       "![Image 21](https://yt3.ggpht.com/ytc/AIdro_lXu0WPAKZ-yH5SnZKCHExCdAJcePDMhjXvJTx1cSpPrDtKH5DKmu4jO0zSfegaYwL4rQ=s88-c-k-c0x00ffffff-no-rj)\n",
       "\n",
       "### [@python2030-oh4fc](https://www.youtube.com/@python2030-oh4fc)\n",
       "\n",
       "[7 days ago](https://www.youtube.com/watch?v=vK_SxyqIfwk&lc=Ugz2b2EKXi_NZZIcp7F4AaABAg)\n",
       "\n",
       "![Image 22: ❤](https://www.youtube.com/s/gaming/emoji/7ff574f2/emoji_u2764.png)![Image 23: 🎉](https://www.youtube.com/s/gaming/emoji/7ff574f2/emoji_u1f389.png)\n",
       "\n",
       "Show less Read more\n",
       "\n",
       " Like \n",
       "\n",
       " 1 \n",
       "\n",
       " Dislike \n",
       "\n",
       "Reply\n",
       "\n",
       "![Image 24](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "Comments 1\n",
       "----------\n",
       "\n",
       "[Top comments](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)[Newest first](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "![Image 25](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "Key moments\n",
       "-----------\n",
       "\n",
       "[![Image 26](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Aishwarya’s career journey from finance to self-driving AI #### Aishwarya’s career journey from finance to self-driving AI 0:51](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=51s)\n",
       "\n",
       "[#### Aishwarya’s career journey from finance to self-driving AI](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=51s)\n",
       "\n",
       "0:51\n",
       "\n",
       "[![Image 27](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Building AI guide dog for the visually impaired #### Building AI guide dog for the visually impaired 5:45](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=345s)\n",
       "\n",
       "[#### Building AI guide dog for the visually impaired](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=345s)\n",
       "\n",
       "5:45\n",
       "\n",
       "[![Image 28](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Exploring LiDAR, radar, and Tesla’s camera-based approach #### Exploring LiDAR, radar, and Tesla’s camera-based approach 12:03](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=723s)\n",
       "\n",
       "[#### Exploring LiDAR, radar, and Tesla’s camera-based approach](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=723s)\n",
       "\n",
       "12:03\n",
       "\n",
       "[![Image 29](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Trust, regulation, and challenges in self-driving adoption #### Trust, regulation, and challenges in self-driving adoption 16:24](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=984s)\n",
       "\n",
       "[#### Trust, regulation, and challenges in self-driving adoption](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=984s)\n",
       "\n",
       "16:24\n",
       "\n",
       "[![Image 30](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Waymo, ride-hailing, and gesture recognition for traffic control #### Waymo, ride-hailing, and gesture recognition for traffic control 19:39](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1179s)\n",
       "\n",
       "[#### Waymo, ride-hailing, and gesture recognition for traffic control](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1179s)\n",
       "\n",
       "19:39\n",
       "\n",
       "[![Image 31](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Malaria mapping in Africa and AI for social good #### Malaria mapping in Africa and AI for social good 24:18](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1458s)\n",
       "\n",
       "[#### Malaria mapping in Africa and AI for social good](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1458s)\n",
       "\n",
       "24:18\n",
       "\n",
       "[![Image 32](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Deployment, safety, and testing in self-driving systems #### Deployment, safety, and testing in self-driving systems 29:40](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1780s)\n",
       "\n",
       "[#### Deployment, safety, and testing in self-driving systems](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1780s)\n",
       "\n",
       "29:40\n",
       "\n",
       "[![Image 33](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Transition from NLP to computer vision and deep learning #### Transition from NLP to computer vision and deep learning 37:00](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=2220s)\n",
       "\n",
       "[#### Transition from NLP to computer vision and deep learning](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=2220s)\n",
       "\n",
       "37:00\n",
       "\n",
       "[![Image 34](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Reinforcement learning, robotics, and self-driving constraints #### Reinforcement learning, robotics, and self-driving constraints 43:37](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=2617s)\n",
       "\n",
       "[#### Reinforcement learning, robotics, and self-driving constraints](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=2617s)\n",
       "\n",
       "43:37\n",
       "\n",
       "[![Image 35](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Testing processes, evaluations, and staged rollouts for autonomous driving #### Testing processes, evaluations, and staged rollouts for autonomous driving 51:28](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=3088s)\n",
       "\n",
       "[#### Testing processes, evaluations, and staged rollouts for autonomous driving](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=3088s)\n",
       "\n",
       "51:28\n",
       "\n",
       "[![Image 36](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Can multimodal LLMs be applied to self-driving? #### Can multimodal LLMs be applied to self-driving? 52:53](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=3173s)\n",
       "\n",
       "[#### Can multimodal LLMs be applied to self-driving?](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=3173s)\n",
       "\n",
       "52:53\n",
       "\n",
       "[![Image 37](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### How to get started in self-driving AI careers #### How to get started in self-driving AI careers 55:33](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=3333s)\n",
       "\n",
       "[#### How to get started in self-driving AI careers](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=3333s)\n",
       "\n",
       "55:33\n",
       "\n",
       "Sync to video time\n",
       "\n",
       "![Image 38](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "Description\n",
       "-----------\n",
       "\n",
       "Lessons from Applied AI: Tesla, Waymo, and Beyond - Aishwarya Jadhav\n",
       "\n",
       "In this episode, we talked with Aishwarya Jadhav, a machine learning engineer whose career has spanned Morgan Stanley, Tesla, and now Waymo. Aishwarya shares her journey from big data in finance to applied AI in self-driving, gesture understanding, and computer vision. She discusses building an AI guide dog for the visually impaired, contributing to malaria mapping in Africa, and the challenges of deploying safe autonomous systems. We also explore the intersection of computer vision, NLP, and LLMs, and what it takes to break into the self-driving AI industry. TIMECODES [00:51](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=51s) Aishwarya’s career journey from finance to self-driving AI [05:45](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=345s) Building AI guide dog for the visually impaired [12:03](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=723s) Exploring LiDAR, radar, and Tesla’s camera-based approach [16:24](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=984s) Trust, regulation, and challenges in self-driving adoption [19:39](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1179s) Waymo, ride-hailing, and gesture recognition for traffic control [24:18](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1458s) Malaria mapping in Africa and AI for social good [29:40](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=1780s) Deployment, safety, and testing in self-driving systems [37:00](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=2220s) Transition from NLP to computer vision and deep learning [43:37](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=2617s) Reinforcement learning, robotics, and self-driving constraints [51:28](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=3088s) Testing processes, evaluations, and staged rollouts for autonomous driving [52:53](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=3173s) Can multimodal LLMs be applied to self-driving? [55:33](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=3333s) How to get started in self-driving AI careers Connect with Aishwarya \n",
       "*   Linkedin - [![Image 39](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)/aishwaryajadhav8](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbkdzeGxoLTRhQnRtcU43LXpVeEctYVVNS1AyQXxBQ3Jtc0tuN2tadE5zcmp1UkhweExJUzE5akQ3MTFCM3Y0RjFobFNPUGVNMmZuZzhYSWJRRGtYMzNpRGlkRl9rOUd2dW5ZdXF4SG8zQWZ6cFBhcTJBaVJtdk8wemROQzM0Yzc3LUZXZVBOWjhnZlZEV1NiZVRKUQ&q=https%3A%2F%2Fwww.linkedin.com%2Fin%2Faishwaryajadhav8%2F&v=vK_SxyqIfwk)\n",
       "\n",
       " Connect with DataTalks.Club: \n",
       "*   Join the community - [https://datatalks.club/slack.html](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbWtqMjdZTmJNU2xDQW11MmRxa0lCWnFzLXpoZ3xBQ3Jtc0tuQlZmRnVBcVVpU084VmZiTnc1MGp1ZkRSZWhYTGpJY0E2aTVxWFpfb0xCNVk3QW5fM0hTMW5VS1poTTdCeEFFM3EwbTJibEhDaWdGVW9aTkJHcjZCajJHaGdhaE1YdklCUmREWXNPNWdEZjdKVHZkbw&q=https%3A%2F%2Fdatatalks.club%2Fslack.html&v=vK_SxyqIfwk)\n",
       "*   Subscribe to our Google calendar to have all our events in your calendar - [https://calendar.google.com/calendar/...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbXE4YzZjQ2VQMV8yTTF0aVBOV3MtREIzZjFtUXxBQ3Jtc0tsLWlETDRUSzhSRGp5THVKUHdYWWZZZncwVXMyNGJOWHlTQl9sM0hSV2F3MDRLTTNYbHJKaGt6TUxZRXU5N0xmNFFNWUtmb0ZlVGhSYXhsZGI4WUJiLTRWMTV2VGJpcWZ2VjQzRjh0VWRPRTd6VlJSTQ&q=https%3A%2F%2Fcalendar.google.com%2Fcalendar%2Fr%3Fcid%3DZjhxaWRqbnEwamhzY3A4ODA5azFlZ2hzNjBAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&v=vK_SxyqIfwk)\n",
       "*   Check other upcoming events - [https://lu.ma/dtc-events](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbXBqQWRhRGo3ZExiSHdBdnAtZXAzUGNORnNjQXxBQ3Jtc0tuV1VmU0VtRi1pWjRFcHlzYmdBZ01hTUd3MFRjWHZ1UFMzWTJjR0l5djNjZnVzX1ZDZ1JqclA5QlBaa3Vqd1RrSDM4UHQ3cW5uVWNuekhLeXhNR2I4dGM3TTFpWGM1ekl4VFlfS1czNGJQbV9jUVdYTQ&q=https%3A%2F%2Flu.ma%2Fdtc-events&v=vK_SxyqIfwk)\n",
       "*   GitHub: [https://github.com/DataTalksClub](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa2V0VHdWMkdKY0c5ZUZMZjZqVXZwR3dMVkl5Z3xBQ3Jtc0tuenZXeVF5RmpCRXZ3U3g3MDVaQTRscEFOWEI1UVhLVnl2MExUelRuTnJ1aTBuQklQeFNiWE83WG12SVF6OEo5U2dReGYtRUR1NVhPeTRMTEVlUUVxWVg3cUY0WlZFRkFFa0taQS1mUzVlUkxaNjZPWQ&q=https%3A%2F%2Fgithub.com%2FDataTalksClub&v=vK_SxyqIfwk)\n",
       "*   LinkedIn - [![Image 40](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)/datatalks-club](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbTdpcHNrZ2hoakRSWElzZmh5MXhDdVJfZGk4QXxBQ3Jtc0tuZS1TQnFCM1R1bmpqS3gxMzNTakdjM1EyRHhLLTUzOEJOaXViWU9WaGVuYXpoam1UYjlzRDlFbTFFUHg3OFZjLWRIcEZyY3VHazQ5cVUtcXJSblQ0dkwxSzhoMERtbVFQekFHaFdrVVp1UWF4RlpfUQ&q=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Fdatatalks-club%2F&v=vK_SxyqIfwk)\n",
       "*   Twitter - [![Image 41](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)/datatalksclub](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa2NEUTdoU0RVeHlvOHdWWGpla3AwX3NRcXZUd3xBQ3Jtc0ttcnRyenJIRUZPTHBWblpHZzZHM2J1LUlFTmxnWnloaFMzbml6WXZDbklWTnNfS0hVb0lCcEtVUlFfc1FNZENsQmNFNXEwc2JEdmRQSzlBZC1nRGM2bDBOZnhPWmtEd211WDFFeHJWa0xTNXktTm5Jaw&q=https%3A%2F%2Ftwitter.com%2FDataTalksClub&v=vK_SxyqIfwk)\n",
       "*   Website - [https://datatalks.club/](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa3VwU2VLQlJoNHU2YldMV0s3Unk2dnJ6WEtSQXxBQ3Jtc0ttcTdveG5zOGo3clpRZ0tLcng3QWRnYWRwZFIzR2ltOHFqcE1CTFZaZ2RkTENaRFUxMFNaZkNuS04wOEIta1FxQlZjNGgzSG82NHhNazBoOURuWkZ1TXRWYjBaa0tiZDNEQzBYU1hKRWFHMkNQLUg1Zw&q=https%3A%2F%2Fdatatalks.club%2F&v=vK_SxyqIfwk)\n",
       "\n",
       " Connect with Alexey \n",
       "*   Twitter - [![Image 42](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)/al_grigor](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbDNHaU55WHoxdVpHNjh1ekdJOFBxeHNoMnhJZ3xBQ3Jtc0tsT0RYUlk4Y0JXeFRPUVcxWWJyNjZycVo3b2lqWDg1RkFCSk83Y0VHbzVrM0FQVXRNNWdKaVo3Y0hjV1FXWUNEVkZwbFF0UFlBRW54NEJvQkpRTFRjNjhQUjRDeWdXNjhTQi1DNWc0STV5aTRPc2Y1cw&q=https%3A%2F%2Ftwitter.com%2FAl_Grigor&v=vK_SxyqIfwk)\n",
       "*   Linkedin - [![Image 43](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)/agrigorev](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbW0xTXppV1NKX3RLWFpueTRhWmc4YVREV1F3Z3xBQ3Jtc0trZld4RXczX2V0VWlRZTV4amxEbTg4aUpONTRJQklPMjRtWXVhVnhiQzFNVkVVV1RBSEJuOVl1aVpHdzlZaTMzRGVBRkZDbk03aXZyWDQtaDJRZDZOWXpLazk2dkU4ek40ZUZHR1dOOExaTGxrdTlIVQ&q=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fagrigorev%2F&v=vK_SxyqIfwk)\n",
       "\n",
       " Check our free online courses: \n",
       "*   ML Engineering course - [http://mlzoomcamp.com](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbGR3OUowdkt6WVhZRVotMHBTOEQ1NU9wYjdGQXxBQ3Jtc0tucmFwV0RxazQtcnY0d3ZqUk9JeEVXZDVFZXQ5cll6VXhGZ2pPZmRVekpwd3BQOFFEanFlNHNUX3BlZUdwaHQ3S2tCbmJMeXBvZWtHVC1xdHNqcHpEZmJILXhKN0E5b2pQWVFLLTNPU3VRNU5ubXlUcw&q=http%3A%2F%2Fmlzoomcamp.com%2F&v=vK_SxyqIfwk)\n",
       "*   Data Engineering course - [https://github.com/DataTalksClub/data...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbFhFbG5WMDZ6SlBqdXZOb1dDRG9KbzBQdG0zd3xBQ3Jtc0tuSkRMNnFMMmhRNE9sdGNrMmZ3ZGF6aEltLUxlWEFBT2ZwU1RVWGhLZXNmdmt5VlZKTGJ3dkJtaTlNempVMWJKVlB2a25YVjVIRGRac0V3RHN0M1BZNzNweHpYNkFaQlpKZGJxN2toSVNVZWFyTl9Saw&q=https%3A%2F%2Fgithub.com%2FDataTalksClub%2Fdata-engineering-zoomcamp&v=vK_SxyqIfwk)\n",
       "*   MLOps course - [https://github.com/DataTalksClub/mlop...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbHBWUEJIajQ2aWRHQkltYTYwZF9yQTFENnFfZ3xBQ3Jtc0tseld5VVVSVkpqTDlHTmx5dF9NekticDlkQlVMcExjamxsUTRZblhDSEhCeW9lR3hIZ3VTS3BwcVgwOWpsWk00VFNLU0dBMlhMUnZ6U204b1JlVGw2eGYybE1ETVktR19JZVBsRGY1ZXJjZldTN1FRbw&q=https%3A%2F%2Fgithub.com%2FDataTalksClub%2Fmlops-zoomcamp&v=vK_SxyqIfwk)\n",
       "*   LLM course - [https://github.com/DataTalksClub/llm-...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbE8tTXVLU3NnVnV5Z25CM3V5Z0tFZHNFcDR3UXxBQ3Jtc0tsaTBuWmpIb0ptZkF6OUtySDdHNVJYRVI2cU9WZkJnNzB4WlJZVG1RTS1Eak00VFI3OTJHZmtzdjQ2MUhRbUNnWjJSSFV0XzI5RnNuS3BZZkpoVXdBcDZyUW9BZnlHSDlhRnNBZTNMSzRIaklPd1otOA&q=https%3A%2F%2Fgithub.com%2FDataTalksClub%2Fllm-zoomcamp&v=vK_SxyqIfwk)\n",
       "*   Open-source LLM course: [https://github.com/DataTalksClub/open...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbjJBSzBVQnhQT09RLS1XVU5EdVBBQ2xqcWh4Z3xBQ3Jtc0tuQzRQZ3BpWUpSNjNwb3p3VGdpemI4cEJlcF9ScVdUemZNbnZsd1djNG15LXRqaW4wN0tocGhoeXhGTjY3UkZqSVVvYl9JVnBQVFQ4cU4zSFYwR2txdHp5NVJJVjhiM2VvdnN5NnZyNE9GUVdnQjlGRQ&q=https%3A%2F%2Fgithub.com%2FDataTalksClub%2Fopen-source-llm-zoomcamp&v=vK_SxyqIfwk)\n",
       "*   AI Dev Tools course: [https://github.com/DataTalksClub/ai-d...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbGhpb3prNW5rQ0NZcWlJX0RNN1BoZHAyemZBQXxBQ3Jtc0ttV0V5d1NYS3lfbE1BTHJ2ekh3U1U0eHUyQTRuUXk2UHZucUxqS3N5aklXT2tqSXhzSEhhaVE5eTh1RUNFNzhxMEcyazRUWXR3N0hLNmdhbkZsSDNkMGpmVUtkcHlMdDhZM2VkYjJ1RUdRVFBYYVRHOA&q=https%3A%2F%2Fgithub.com%2FDataTalksClub%2Fai-dev-tools-zoomcamp&v=vK_SxyqIfwk)\n",
       "\n",
       " 👉🏼 Read about all our courses in one place - [https://datatalks.club/blog/guide-to-...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbVQwNzQ1bFc1a3lIV2ExaWNKOVp3b202NVZGd3xBQ3Jtc0tsT2tkNUl4cmFlVEJpUE55SVhpc0V0S1hKZjV1eEwzTG9rQXpXQWFQRUhsTDhsc2NNYzNyYWZxMTJ5SUNmSU44NkdPdnp6VjFFNGpYUlMteG1LdEJydFRGXzRodHIzZ0dRMmRnZzBBNU5tUHdoMkR4MA&q=https%3A%2F%2Fdatatalks.club%2Fblog%2Fguide-to-free-online-courses-at-datatalks-club.html&v=vK_SxyqIfwk) 👋🏼 Support/inquiries If you want to support our community, use this link - [https://github.com/sponsors/alexeygri...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbjZMZzI0OUM1czkwU0NLeGZ5aFV4Qm94bEl6d3xBQ3Jtc0tsdk5MRTRzRDZOWFhfZTBsN3JrRDAxQ1kza3FXTGdzTENvVDh2bGJqbzBTRHg0Z2prSXpSTERRbUFFWmFXSmwzODRnbEwtbTN5ZFNnUFQ2aTZVRU5oM2FyQWtYa0JuVmNPQ2FQdmpBZGNjR1h2dEdhOA&q=https%3A%2F%2Fgithub.com%2Fsponsors%2Falexeygrigorev&v=vK_SxyqIfwk) If you’re a company, reach us at alexey@datatalks.club…...more \n",
       "\n",
       "...more Show less \n",
       "\n",
       "Key moments\n",
       "\n",
       "View all\n",
       "-----------------------\n",
       "\n",
       "[![Image 44](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Aishwarya’s career journey from finance to self-driving AI #### Aishwarya’s career journey from finance to self-driving AI 0:51](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=51s)\n",
       "\n",
       "[#### Aishwarya’s career journey from finance to self-driving AI](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=51s)\n",
       "\n",
       "0:51\n",
       "\n",
       "[![Image 45](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Building AI guide dog for the visually impaired #### Building AI guide dog for the visually impaired 5:45](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=345s)\n",
       "\n",
       "[#### Building AI guide dog for the visually impaired](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=345s)\n",
       "\n",
       "5:45\n",
       "\n",
       "[![Image 46](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Exploring LiDAR, radar, and Tesla’s camera-based approach #### Exploring LiDAR, radar, and Tesla’s camera-based approach 12:03](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=723s&pp=0gcJCdcCDuyUWbzu)\n",
       "\n",
       "[#### Exploring LiDAR, radar, and Tesla’s camera-based approach](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=723s&pp=0gcJCdcCDuyUWbzu)\n",
       "\n",
       "12:03\n",
       "\n",
       "[![Image 47](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) #### Trust, regulation, and challenges in self-driving adoption #### Trust, regulation, and challenges in self-driving adoption 16:24](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=984s&pp=0gcJCdcCDuyUWbzu)\n",
       "\n",
       "[#### Trust, regulation, and challenges in self-driving adoption](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=984s&pp=0gcJCdcCDuyUWbzu)\n",
       "\n",
       "16:24\n",
       "\n",
       "Explore the podcast\n",
       "\n",
       "[![Image 48](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)191 episodes 191 episodes](https://www.youtube.com/playlist?list=PL3MmuxUbc_hK60wsCyvrEK2RjQsUi4Oa_)\n",
       "\n",
       "DataTalks.Club Podcast\n",
       "\n",
       "DataTalksClub ⬛\n",
       "\n",
       "[![Image 49](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) Podcasts](https://www.youtube.com/podcasts)\n",
       "\n",
       "Transcript\n",
       "\n",
       "Follow along using the transcript.\n",
       "\n",
       "Show transcript\n",
       "\n",
       "[![Image 50](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) ### DataTalksClub ⬛ 66.7K subscribers](https://www.youtube.com/@DataTalksClub)\n",
       "\n",
       "[Videos](https://www.youtube.com/channel/UCDvErgK0j5ur3aLgn6U-LqQ/videos)\n",
       "\n",
       "[About](https://www.youtube.com/channel/UCDvErgK0j5ur3aLgn6U-LqQ/about)\n",
       "\n",
       "[Videos](https://www.youtube.com/channel/UCDvErgK0j5ur3aLgn6U-LqQ/videos)[About](https://www.youtube.com/channel/UCDvErgK0j5ur3aLgn6U-LqQ/about)[![Image 51](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) Twitter](https://www.youtube.com/redirect?event=Watch_SD_EP&redir_token=QUFFLUhqa0FHdFRxZk1kMWVXQ1g3ZG82OWdxUWp0Y202d3xBQ3Jtc0tsX0pEa3psY3dHZkhvRkstdEd1cG12cm1KQmpnWWhMNDFQWWgwaGlWVTl2OFJxazd5enV6NENUdHlLaVBLWkpIUGM0MTAwNXgwZUdHZ2pianh4UnJmM2VTemktMG1weTJkb3pkVjBQdm1haGdSNzJ0aw&q=https%3A%2F%2Ftwitter.com%2FDataTalksClub)[![Image 52](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) LinkedIn](https://www.youtube.com/redirect?event=Watch_SD_EP&redir_token=QUFFLUhqbDFuQ05RQzltSmhvdTIwLXFRbGdpbTBLZDdEUXxBQ3Jtc0tuQUZmVkhueXVhbDVmOURDcWxLTElrbEQtQzR6ZXJScjY2bGUzckJoSndRbktoSmVCZlVwRzJUOGhsRDVycFowUG1VS2RqM2ZIOW5IRndvN2d2aU1WSlV2QjhJNlphQV9SRjZYaTVESWNLRVhXR1V3Zw&q=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Fdatatalks-club%2F)\n",
       "\n",
       "![Image 53](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "Transcript\n",
       "----------\n",
       "\n",
       "NaN / NaN\n",
       "\n",
       "Live chat replay is not available for this video.\n",
       "\n",
       "[![Image 54](https://i.ytimg.com/vi/RxuSvyOwVCI/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLB5ipyYmb1xDP4DCVvcxQUsr_X73g) 30:50](https://www.youtube.com/watch?v=RxuSvyOwVCI)\n",
       "\n",
       "![Image 55](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [New Colossus: The World’s Largest AI Datacenter Isn’t What It Seems](https://www.youtube.com/watch?v=RxuSvyOwVCI)\n",
       "\n",
       "Anastasi In Tech\n",
       "\n",
       "569K views • 2 weeks ago\n",
       "\n",
       "[![Image 56](https://i.ytimg.com/vi/P_fHJIYENdI/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLAUN9VnIsRf-WRgIsa1hrasnzDXlQ) 24:52](https://www.youtube.com/watch?v=P_fHJIYENdI)\n",
       "\n",
       "![Image 57](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [AlphaFold - The Most Useful Thing AI Has Ever Done](https://www.youtube.com/watch?v=P_fHJIYENdI)\n",
       "\n",
       "Veritasium\n",
       "\n",
       "9.7M views • 8 months ago\n",
       "\n",
       "[![Image 58](https://i.ytimg.com/vi/zwu4fJ_eeq8/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLBl7E40BUpDQRErJZ86TcsNXJDgBw) 13:44](https://www.youtube.com/watch?v=zwu4fJ_eeq8)\n",
       "\n",
       "![Image 59](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Trump Can’t Stop Blaming and Bragging, Fox News Has a Grip on Him & We See His \"Hellhole\" Cities](https://www.youtube.com/watch?v=zwu4fJ_eeq8)\n",
       "\n",
       "Jimmy Kimmel Live\n",
       "\n",
       "2.6M views • 21 hours ago\n",
       "\n",
       "New\n",
       "\n",
       "[![Image 60](https://i.ytimg.com/vi/WuTJkFvw70o/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCnxaue7Cf2xAIYjXnJ7xg4coW24w) 45:29](https://www.youtube.com/watch?v=WuTJkFvw70o)\n",
       "\n",
       "![Image 61](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Mark Zuckerberg on AI Glasses, Superintelligence, Neural Control, and More](https://www.youtube.com/watch?v=WuTJkFvw70o)\n",
       "\n",
       "Rowan Cheung\n",
       "\n",
       "131K views • 4 weeks ago\n",
       "\n",
       "[![Image 62](https://i.ytimg.com/vi/C44iCr6czAo/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLBqjNq5uD9gFsXGxO33e-BjR0_eOw) 24:24](https://www.youtube.com/watch?v=C44iCr6czAo)\n",
       "\n",
       "![Image 63](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Windows 11 Is a Lost Cause. Truly Destined for the Garbage. Don't Upgrade from 10](https://www.youtube.com/watch?v=C44iCr6czAo)\n",
       "\n",
       "Rob Braxman Tech\n",
       "\n",
       "242K views • 2 days ago\n",
       "\n",
       "New\n",
       "\n",
       "[![Image 64](https://i.ytimg.com/vi/79-bApI3GIU/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLBhBFgtw2MEeH58oVlonBzKqd8RvQ) 18:14](https://www.youtube.com/watch?v=79-bApI3GIU)\n",
       "\n",
       "![Image 65](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Ex-OpenAI Scientist WARNS: \"You Have No Idea What's Coming\"](https://www.youtube.com/watch?v=79-bApI3GIU)\n",
       "\n",
       "AI Upload\n",
       "\n",
       "3.7M views • 3 months ago\n",
       "\n",
       "[![Image 66](https://i.ytimg.com/vi/EkuVqdj8O6E/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCacQ44_3aMJMydFYO7Fn7EURU2iw) 28:58](https://www.youtube.com/watch?v=EkuVqdj8O6E)\n",
       "\n",
       "![Image 67](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Eric Schmidt on AI, the Battle with China, and the Future of America](https://www.youtube.com/watch?v=EkuVqdj8O6E)\n",
       "\n",
       "All-In Podcast\n",
       "\n",
       "504K views • 3 weeks ago\n",
       "\n",
       "[![Image 68](https://i.ytimg.com/vi/gIxq03dipUw/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLCO3f8VMQhdXpkp7QB7-jNkyCUVVQ) 16:01](https://www.youtube.com/watch?v=gIxq03dipUw)\n",
       "\n",
       "![Image 69](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [ChatGPT in a robot does exactly what experts warned](https://www.youtube.com/watch?v=gIxq03dipUw)\n",
       "\n",
       "InsideAI\n",
       "\n",
       "1.8M views • 3 weeks ago\n",
       "\n",
       "[![Image 70](https://i.ytimg.com/vi/_2NijXqBESI/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLC9vkqYlFGvMiXUnHUx_BKOu-pitg) 17:34](https://www.youtube.com/watch?v=_2NijXqBESI)\n",
       "\n",
       "![Image 71](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [The Physical Turing Test: Jim Fan on Nvidia's Roadmap for Embodied AI](https://www.youtube.com/watch?v=_2NijXqBESI)\n",
       "\n",
       "Sequoia Capital\n",
       "\n",
       "443K views • 5 months ago\n",
       "\n",
       "[![Image 72](https://i.ytimg.com/vi/kqaMIFEz15s/hqdefault.jpg?sqp=-oaymwEmCKgBEF5IWvKriqkDGQgBFQAAiEIYAdgBAeIBCggYEAIYBjgBQAE=&rs=AOn4CLBaR2viaedIhr5pJvQLetOkHZdWYg) 16:55](https://www.youtube.com/watch?v=kqaMIFEz15s)\n",
       "\n",
       "![Image 73](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Cybersecurity Trends for 2025 and Beyond](https://www.youtube.com/watch?v=kqaMIFEz15s)\n",
       "\n",
       "IBM Technology\n",
       "\n",
       "709K views • 9 months ago\n",
       "\n",
       "[![Image 74](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 59:33](https://www.youtube.com/watch?v=x2AAjqz2XmM)\n",
       "\n",
       "![Image 75](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Building reliable AI products in the era of Gen AI and Agents - Ranjitha Kulkarni](https://www.youtube.com/watch?v=x2AAjqz2XmM)\n",
       "\n",
       "DataTalksClub ⬛\n",
       "\n",
       "758 views • Streamed 3 weeks ago\n",
       "\n",
       "[![Image 76](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 9:18](https://www.youtube.com/watch?v=lZ_WIvCfll8)\n",
       "\n",
       "![Image 77](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [What Exactly Happened On SpaceX's ELEVENTH Starship Test Flight!](https://www.youtube.com/watch?v=lZ_WIvCfll8)\n",
       "\n",
       "The Space Race\n",
       "\n",
       "188K views • 1 day ago\n",
       "\n",
       "New\n",
       "\n",
       "[![Image 78](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 23:28](https://www.youtube.com/watch?v=UAT-eOzeY4M)\n",
       "\n",
       "![Image 79](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [The genius logic of the NATO phonetic alphabet](https://www.youtube.com/watch?v=UAT-eOzeY4M)\n",
       "\n",
       "RobWords\n",
       "\n",
       "3M views • 5 days ago\n",
       "\n",
       "New\n",
       "\n",
       "[![Image 80](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 1:07:09](https://www.youtube.com/watch?v=21EYKqUsPfg)\n",
       "\n",
       "![Image 81](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Richard Sutton – Father of RL thinks LLMs are a dead end](https://www.youtube.com/watch?v=21EYKqUsPfg)\n",
       "\n",
       "Dwarkesh Patel\n",
       "\n",
       "380K views • 2 weeks ago\n",
       "\n",
       "[![Image 82](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 47:37](https://www.youtube.com/watch?v=l8_08bN9Tsg)\n",
       "\n",
       "![Image 83](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Politics Chat, October 16, 2025](https://www.youtube.com/watch?v=l8_08bN9Tsg)\n",
       "\n",
       "Heather Cox Richardson\n",
       "\n",
       "35K views • Streamed 2 hours ago\n",
       "\n",
       "New\n",
       "\n",
       "[![Image 84](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 19:51](https://www.youtube.com/watch?v=rBlCOLfMYfw)\n",
       "\n",
       "![Image 85](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [The Limits of AI: Generative AI, NLP, AGI, & What’s Next?](https://www.youtube.com/watch?v=rBlCOLfMYfw)\n",
       "\n",
       "IBM Technology\n",
       "\n",
       "140K views • 9 days ago\n",
       "\n",
       "[![Image 86](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 21:14](https://www.youtube.com/watch?v=pDj1QhPOVBo)\n",
       "\n",
       "![Image 87](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Why I Left Quantum Computing Research](https://www.youtube.com/watch?v=pDj1QhPOVBo)\n",
       "\n",
       "Looking Glass Universe\n",
       "\n",
       "886K views • 3 months ago\n",
       "\n",
       "[![Image 88](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 1:34:30](https://www.youtube.com/watch?v=4eCFmbX5rAQ)\n",
       "\n",
       "![Image 89](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Larry Ellison Keynote on Oracle's Vision and Strategy: Oracle AI World 2025](https://www.youtube.com/watch?v=4eCFmbX5rAQ)\n",
       "\n",
       "Oracle\n",
       "\n",
       "57K views • Streamed 2 days ago\n",
       "\n",
       "New\n",
       "\n",
       "[![Image 90](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 42:12](https://www.youtube.com/watch?v=GhIJs4zbH0o)\n",
       "\n",
       "![Image 91](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Inside OpenAI's Stargate Megafactory with Sam Altman | The Circuit](https://www.youtube.com/watch?v=GhIJs4zbH0o)\n",
       "\n",
       "Bloomberg Originals\n",
       "\n",
       "5.4M views • 4 months ago\n",
       "\n",
       "[![Image 92](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s) 20:57](https://www.youtube.com/watch?v=5KmopXwjXik)\n",
       "\n",
       "![Image 93](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "\n",
       "### [Godfather of AI WARNS: \"You Have No Idea What's Coming\"](https://www.youtube.com/watch?v=5KmopXwjXik)\n",
       "\n",
       "The Diary Of A CEO Clips\n",
       "\n",
       "2.8M views • 2 weeks ago\n",
       "\n",
       "Show more\n",
       "\n",
       "[[](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)](https://www.youtube.com/watch?v=vK_SxyqIfwk&t=172s)\n",
       "</pre>\n",
       "            </div>\n",
       "\n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The video titled <strong>&quot;Lessons from Applied AI: Tesla, Waymo, and Beyond&quot;</strong> featuring <strong>Aishwarya Jadhav</strong> is a discussion exploring her career journey and experiences in the field of artificial intelligence, particularly in applications related to self-driving technology.</p>\n",
       "<h3>Key Highlights:</h3>\n",
       "<ul>\n",
       "<li><strong>Career Journey</strong>: Aishwarya shares her transition from working with big data in finance at Morgan Stanley to her roles at Tesla and Waymo, focusing on applied AI.</li>\n",
       "<li><strong>Technological Insights</strong>: She discusses various technologies, including the development of AI guide dogs for the visually impaired and approaches to self-driving technology using LiDAR, radar, and camera systems.</li>\n",
       "<li><strong>Challenges in Adoption</strong>: The conversation touches on critical topics such as trust, regulation, and the challenges of deploying safe autonomous systems.</li>\n",
       "<li><strong>Social Impact</strong>: Aishwarya talks about contributions to malaria mapping in Africa, showcasing AI's potential for social good.</li>\n",
       "<li><strong>Future in AI</strong>: There is a discussion on the intersection of computer vision, natural language processing, and large language models (LLMs) as well as tips for those looking to enter the self-driving AI industry.</li>\n",
       "</ul>\n",
       "<p>For more detailed insights, you can watch the full video <a href=\"https://www.youtube.com/watch?v=vK_SxyqIfwk&amp;t=172s\">here</a>.</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "await runner.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c0a02-e0f5-45ea-9518-8af6b437cf37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
